{
    "project": "openbmc/docs",
    "branch": "master",
    "topic": "design",
    "id": "Ie6579503609857b8c6abf4702cba852ac490b40d",
    "number": 53809,
    "subject": "Design proposal for NVMe OOB management",
    "owner": {
        "name": "Hao Jiang",
        "email": "jianghao@google.com",
        "username": "drakedog2008"
    },
    "url": "https://gerrit.openbmc.org/c/openbmc/docs/+/53809",
    "hashtags": [],
    "createdOn": 1652921588,
    "lastUpdated": 1704912704,
    "open": true,
    "status": "NEW",
    "comments": [
        {
            "timestamp": 1652921588,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 1."
        },
        {
            "timestamp": 1652921684,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Topic set to design"
        },
        {
            "timestamp": 1653015866,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Patch Set 1: Code-Review-1\n\n(9 comments)"
        },
        {
            "timestamp": 1653321180,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(21 comments)"
        },
        {
            "timestamp": 1654202016,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1656290268,
            "reviewer": {
                "name": "Jeremy Kerr",
                "email": "jk@ozlabs.org",
                "username": "jk-ozlabs"
            },
            "message": "Patch Set 1:\n\n(6 comments)"
        },
        {
            "timestamp": 1656351244,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(2 comments)"
        },
        {
            "timestamp": 1657665422,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 2."
        },
        {
            "timestamp": 1657665436,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(18 comments)"
        },
        {
            "timestamp": 1657687515,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 2:\n\n(5 comments)"
        },
        {
            "timestamp": 1657746780,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(3 comments)"
        },
        {
            "timestamp": 1657749733,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(1 comment)"
        },
        {
            "timestamp": 1657751006,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(1 comment)"
        },
        {
            "timestamp": 1657753235,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 2:\n\n(5 comments)"
        },
        {
            "timestamp": 1657845490,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(4 comments)"
        },
        {
            "timestamp": 1658369609,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Patch Set 2:\n\n(1 comment)"
        },
        {
            "timestamp": 1658371277,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 2:\n\n(4 comments)"
        },
        {
            "timestamp": 1658372085,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 2:\n\n(2 comments)"
        },
        {
            "timestamp": 1658374741,
            "reviewer": {
                "name": "Jeremy Kerr",
                "email": "jk@ozlabs.org",
                "username": "jk-ozlabs"
            },
            "message": "Patch Set 2:\n\n(1 comment)"
        },
        {
            "timestamp": 1658452556,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Patch Set 2:\n\n(1 comment)"
        },
        {
            "timestamp": 1658598484,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 2:\n\n(1 comment)"
        },
        {
            "timestamp": 1659394666,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(2 comments)"
        },
        {
            "timestamp": 1659399063,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 2:\n\n(7 comments)"
        },
        {
            "timestamp": 1660176412,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 3."
        },
        {
            "timestamp": 1660176423,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 3:\n\n(6 comments)"
        },
        {
            "timestamp": 1660176438,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 3: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1660176439,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 3: -Ok-To-Test"
        },
        {
            "timestamp": 1660176454,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 3: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-repository/48967/ : SUCCESS"
        },
        {
            "timestamp": 1660176478,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 3:\n\n(2 comments)"
        },
        {
            "timestamp": 1660176561,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 3:\n\n(1 comment)"
        },
        {
            "timestamp": 1660196622,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 3:\n\n(13 comments)"
        },
        {
            "timestamp": 1660200106,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Patch Set 3:\n\n(2 comments)"
        },
        {
            "timestamp": 1660249670,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 3:\n\n(10 comments)"
        },
        {
            "timestamp": 1660249733,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 4."
        },
        {
            "timestamp": 1660249795,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 4:\n\n(1 comment)"
        },
        {
            "timestamp": 1660249807,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 4: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1660249808,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 4: -Ok-To-Test"
        },
        {
            "timestamp": 1660249836,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 4: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-repository/49036/ : SUCCESS"
        },
        {
            "timestamp": 1660250347,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 4:\n\n(1 comment)"
        },
        {
            "timestamp": 1660250656,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 5."
        },
        {
            "timestamp": 1660250692,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 5: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1660250693,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 5: -Ok-To-Test"
        },
        {
            "timestamp": 1660250694,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 4:\n\n(1 comment)"
        },
        {
            "timestamp": 1660250708,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 5: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-repository/49037/ : SUCCESS"
        },
        {
            "timestamp": 1662423913,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Patch Set 5: Code-Review-1\n\n(15 comments)"
        },
        {
            "timestamp": 1662424928,
            "reviewer": {
                "name": "Jeremy Kerr",
                "email": "jk@ozlabs.org",
                "username": "jk-ozlabs"
            },
            "message": "Patch Set 5:\n\n(1 comment)"
        },
        {
            "timestamp": 1662426161,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Patch Set 5:\n\n(1 comment)"
        },
        {
            "timestamp": 1665684498,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 6."
        },
        {
            "timestamp": 1665684545,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 6: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1665684546,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 6: -Ok-To-Test"
        },
        {
            "timestamp": 1665684563,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 6: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-repository/53552/ : SUCCESS"
        },
        {
            "timestamp": 1697233025,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 7: Patch Set 6 was rebased.\n\nOutdated Votes:\n* Verified+1 (copy condition: \"changekind:NO_CHANGE OR changekind:NO_CODE_CHANGE\")\n"
        },
        {
            "timestamp": 1697233046,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 7: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1697233047,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 7: -Ok-To-Test"
        },
        {
            "timestamp": 1697233074,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 7: Verified-1\n\nBuild Failed \n\nhttps://jenkins.openbmc.org/job/ci-repository/74952/ : FAILURE"
        },
        {
            "timestamp": 1697233079,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 8.\n\nOutdated Votes:\n* Verified-1 (copy condition: \"changekind:NO_CHANGE OR changekind:NO_CODE_CHANGE\")\n"
        },
        {
            "timestamp": 1697233091,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 8: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1697233091,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 8: -Ok-To-Test"
        },
        {
            "timestamp": 1697233114,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 8: Verified-1\n\nBuild Failed \n\nhttps://jenkins.openbmc.org/job/ci-repository/74953/ : FAILURE"
        },
        {
            "timestamp": 1697233203,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 9.\n\nOutdated Votes:\n* Verified-1 (copy condition: \"changekind:NO_CHANGE OR changekind:NO_CODE_CHANGE\")\n"
        },
        {
            "timestamp": 1697233216,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 9: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1697233216,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 9: -Ok-To-Test"
        },
        {
            "timestamp": 1697233239,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 9: Verified-1\n\nBuild Failed \n\nhttps://jenkins.openbmc.org/job/ci-repository/74954/ : FAILURE"
        },
        {
            "timestamp": 1697235006,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 10.\n\nOutdated Votes:\n* Verified-1 (copy condition: \"changekind:NO_CHANGE OR changekind:NO_CODE_CHANGE\")\n"
        },
        {
            "timestamp": 1697235047,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 10: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1697235047,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 10: -Ok-To-Test"
        },
        {
            "timestamp": 1697235071,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 10: Verified-1\n\nBuild Failed \n\nhttps://jenkins.openbmc.org/job/ci-repository/74956/ : FAILURE"
        },
        {
            "timestamp": 1697235116,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Uploaded patch set 11: New patch set was added with same tree, parent tree, and commit message as Patch Set 10.\n\nCopied Votes:\n* Verified-1 (copy condition: \"changekind:NO_CHANGE OR changekind:NO_CODE_CHANGE\")\n"
        },
        {
            "timestamp": 1697235152,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 11: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1697235152,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 11: -Ok-To-Test"
        },
        {
            "timestamp": 1697235174,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 11:\n\nBuild Failed \n\nhttps://jenkins.openbmc.org/job/ci-repository/74957/ : FAILURE"
        },
        {
            "timestamp": 1697687318,
            "reviewer": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "message": "Uploaded patch set 12.\n\nOutdated Votes:\n* Verified-1 (copy condition: \"changekind:NO_CHANGE OR changekind:NO_CODE_CHANGE\")\n"
        },
        {
            "timestamp": 1697687352,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 12: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1697687353,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 12: -Ok-To-Test"
        },
        {
            "timestamp": 1697687372,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 12: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-repository/75119/ : SUCCESS"
        },
        {
            "timestamp": 1704912704,
            "reviewer": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "message": "Patch Set 12:\n\n(1 comment)"
        }
    ],
    "patchSets": [
        {
            "number": 1,
            "revision": "56f76956a03e879a682b57dd0bbd56b84e1a15be",
            "parents": [
                "9915e5d21d3009eab284b321fef46f9301a13206"
            ],
            "ref": "refs/changes/09/53809/1",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1652921588,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Hi Hao Jiang, thanks for the proposal. It sounds like we're missing support for a few NVMe use-cases in OpenBMC and that you'd like to resolve that. Great!\n\nI've added some comments around how I think we can work this document to help describe what it is you need. I think that can only be achieved by addressing some structural issues with the text, so -1 for now."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I am back from vacation. Thanks for the suggestion. I will update the doc soon. "
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "+1 for Andrew and Ed's comments - this needs a bit of a rework to start with the problem statement before the solution is defined. Once that's done, we can review with a focus on the proposed design rather than the document structure.\n\nThe major design point will be the relation with the existing implementations; if this can't be implemented as part of one of the existing codebases, then how it would coexist. I suspect that your proposed nvmed exposes a richer set of potentially NVMe-specific management functionality, but we'd need to make that explicit, and describe how that works within the existing systems.\n\nI've added a couple of responses in line with the existing mctp/etc infrastructure too."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 1,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Coming back to this now that I've read through, I think we need to change the title to something representing the problems the proposal is solving, not the name of the proposed solution."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 1,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Ack"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 11,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit, whitespace error."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 11,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Ack"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 17,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "I think this section needs a few changes:\n\n1. It shouldn't mention a proposed solution (nvmed), it's meant to be a problem description\n2. The problems should be discussed in terms of use cases. What function elsewhere in an OpenBMC system would be requesting the GetLogPage or Identity functions? Why?\n3. The description should cover deficiencies in existing support for NVMe drives in OpenBMC, specifically phosphor-nvme and nvmesensor from dbus-sensors\n\nAs a part of dealing with 3, if there's a reason either of those components *shouldn't* contain the support you need, then that also needs to be covered, and argued in the \"Alternatives Considered\" section (the fact the entire content of \"Alternatives Considered\" is \"Stated in the above chapter\" is a bit of a red flag for me in terms of how you've structured your argument here).\n\nIMO the first time we should hear about \"nvmed\" is in the \"Proposed Design\" section."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 17,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "+1 to Arjs comments;  We need to call out the problem being solved here.  The existing solutions ( phosphor-nvme and nvme-sensor) have a way to enumerate nvme resources and put them on dbus, admittedly, in a more simplistic way than we'd like to see, but code can always be added to one of those."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 17,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "ACKed. The design has turned to nvme sensor instead."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 27,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "This is only background if you already consider the design accepted, which isn't the purpose of this document. The purpose of this document is to help you help the community to converge on the architecture of a solution to your problems, where your problems are your use-cases that OpenBMC doesn't currently support.\n\nThings I'd consider background information are the requirements and environment that lead to the existence of both phosphor-nvme and nvmesensor from dbus-sensors."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 27,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Agree. The design is kind of under discussion internally for a while, making it more like a refined-decision when I wrote the proposal. \n\nAlso rephased the section, stripping away the design for nvmed and adding more background topic on phosphor-nvme and nvme sensor."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 27,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "rephased"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 47,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "IMO you need to flip the orientation here to describe these as deficiencies in phopshor-nvme without mentioning nvmed.\n\nYou also need to argue why it's not possible to change the design direction of phosphor-nvme and motivate the need for a third code-base to handle NVMe drives."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 47,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> IMO you need to flip the orientation here to describe these as deficiencies in phopshor-nvme without mentioning nvmed.\n> \n> You also need to argue why it's not possible to change the design direction of phosphor-nvme and motivate the need for a third code-base to handle NVMe drives.\n\n+1 this second sentence.  We already have two nvme-speaking daemons;  phosphor-nvme for static stack, and nvmesensor for entity-manager reactor stacks, from these requirements, it isn't clear why we'd need another.\n\nFWIW, I have no problem if the code for nvme-sensor was completely reworked to support these goals, and it's already a reasonably well tested starting point for this stuff."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 47,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "The argument against the existing nvme project is stated in the alternative section."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 51,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Requirements are behaviours derived from use-cases, not a concrete solution. A concrete solution should follow from the requirements. Again this makes it feel like a write-down-the-decisions document rather than a drive-the-decision-making-process document, but this is the first time I'm hearing of the decision making process."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 51,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Good suggestion. I agree with all you said and I completely rewrite the section. PTAL."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 54,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "What does this mean?  Can you be more specific about what \"initialize\" actually does in this context?  Aren't nvme controllers initialized by default?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 54,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "It means setting up the mctp ep with the discovery protocol. It is part of the enumerating the nvme devices. \n\nIt is rather a implement detail rather than the requirement. So I moved it and detailed in the proposed design section."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 56,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Please be more specific here.  What does \"Basic information\" mean?  Thermals?  Inventory?  Ideally this would be derived from your background section about missing features."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 56,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "+1; this could be more descriptive of the MI command set you're looking to expose."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 56,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Sure. I listed several examples of the status we need. \n\nAnd this section is moved to the Problem Description."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 57,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This also should be more specific.  NVMe-MI commands are called \"admin\" commands in the spec.  Presumably you have a few starter use cases?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 57,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "It looks like this is referring to two separate MI commands sets in the NVMe-MI spec: MI commands, and Admin Commands."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 57,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Yes, Jeremy is right. \n\nThere are bunch of NVMe matrix we need to read from MI commands and Admin commands. \n\nI listed several in the Problem Description."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 60,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "\"consumers\" maybe?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 60,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Ack"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 64,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "This is the kind of thing that needs to go into your problem description, phrased in terms of the fact that OpenBMC doesn't yet support these things."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 64,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "+1"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 64,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Yeah. You are right. This is the new features we are requiring. \n\nMoved to problem section"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This interface already exists, and is called NVME1000.  I suspect we don't need to create a new one, but lets cover that once we've figured out the design here, and how it differs from the existing nvme reactors."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "The NVME1000 is designed for a NVMe thermal sensor who has properties like thresholds. \n\nThe design aims at a totally different type of device and user case. Yeah, let's try to make consent on the daemon first then the new interface may make its sense."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> The NVME1000 is designed for a NVMe thermal sensor who has properties like thresholds. \n\nThermal sensors over nvme-mi is just the first thing it implemented.  \"NVME1000\" is meant to be the interface for \"supports nvme-mi\" and already has quite a different \n\n\n> \n> The design aims at a totally different type of device and user case.\n\nYou're using nvme-mi, over mctp to connect to an SSD and run nvme-mi commands.  It's the same device, same transport, and unless you don't plan to ever implement thermal sensor support, the same use case.\n\n> Yeah, let's try to make consent on the daemon first then the new interface may make its sense.\n\nEven if it's a new daemon, in entity-manager, it would still be an nvme-mi interface, so it would still use nvme1000, but sure, we can take that up in the above."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "It sounds like we can share the NVME1000, if multiple daemons (in case we all agree to have a new one) can share the same configuration. \n\nWe also need to take NVMe over MCTP over PCIe VDM into consideration. It should share the same configuration."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> It sounds like we can share the NVME1000, if multiple daemons (in case we all agree to have a new one) can share the same configuration. \n\nI still don't think we need multiple daemons here, but sure, in terms of this comment, lets get it changed to NVMe1000 and we can discuss other places.\n\n> \n> We also need to take NVMe over MCTP over PCIe VDM into consideration. It should share the same configuration.\n\nLets discuss that when we get there.  Whether or not it's the same config name would depend on the requirements of the features."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Agree. Will change to NVMe1000"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "FWIW, if you want to change it to be NVMe in both places, I think it would make a lot of sense and the implementations could be just support both keys.  NVME1000 is a historical thing, but the 1000 isn't really important in the descriptor."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 71,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Got it. At least, the NVME1000 will be reused for both NVMe-MI via MCTP and NVMe basic daemon config."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 90,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit, this can probably be removed.  This is an existing feature of entity-manager, and doesn't really have anything to do with this design."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 90,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "VPDless NVMe device is against the spec, so we are eliminating the use case here."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 101,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This is an example of something we generally shouldn't be doing, and doesn't really seem to have any requirements backing it.\n\nAs a rule, we should not be putting protocol-specific things (like mctp) on dbus, because it limits our ability to add new protocols going forward.\n\nThere is one counter example that I'm aware of (ipmb) and even in that case, we would not have built it that way today, and ideally we will migrate away from it in the future.\n\n\nThis interface should be exposing high level primitives, like storage, sensors, ect."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 101,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "> This is an example of something we generally shouldn't be doing, and doesn't really seem to have any requirements backing it.\n\nJust to clarify the separation of components here - the MCTP endpoint interfaces are not provided my this new (nvmed) design, but by the general MCTP infrastructure (mctpd), which nvmed should be using to discover the results of the MCTP enumeration process.\n\nThis dbus interface is already an accepted design; the presence of the MCTP endpoints is defined at https://github.com/openbmc/phosphor-dbus-interfaces/tree/master/yaml/xyz/openbmc_project/MCTP , and the mctpd interface at https://github.com/CodeConstruct/mctp#mctpd-usage .\n\nIn this section, I believe Hao is just using this to describe what interfaces nvmed is using, rather that what it is providing."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 101,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> , but by the general MCTP infrastructure (mctpd), which nvmed should be using to discover the results of the MCTP enumeration process.\n\nThis is roughly the same design that we did for IPMB that I thought we kind of agreed caused more problems than it solved, but Jeremy is certainly more of an expert here than I am, so I'll defer to his good judgement.\n\nWith that said, I wasn't aware that the mctpd->dbus design had been accepted, so that changes this a bit.  In terms of this design, can we just get this section removed, and the mctpd design doc/interfaces put in the background section?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 101,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I tried to give the reader a first impression of how mctp ep is initiated from dbus. Maybe redirect to the MCTPd doc is a good idea. \n\nRemove the interface example and add mctpd link in the background"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 110,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit, more whitespace issues."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 110,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Ack"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "I don't have strong opinions here, but I'd like to see some input from Jeremy and Matt."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "I really don't think an MCTP-specific EM config type benefits us going forward over having more specific types (NVMe-MI, PLDM, RDE, ect).\n\nCan you think of a case where say, an nvme drive and a RDE accelerator would share code or configurations here?  Even if there were sharing, I suspect they would be minimal."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "Yep, I think the NVMe(-MI) level is most suitable here. I dont see a need to expose much in the way of MCTP-specific configuration, as we already have the discovery process (MCTP Control Protocol) for that, the results of which are exposed via dbus anyway."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "FWIW, also, in the case where we had a device that supported more than one of the set of nvme-mi, pldm, and RDE, we would still have a way to declare it (just declare all 3 exposes records)."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "If the device support multiple mctp type, will that be a problem we have multiple configuration for daemons (nvme, spdm etc) to initialize the same mctp ep?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "The point of exposes records is they describe the interfaces that the drive supports.  In terms of the configuration data, no, it wouldn't be a problem for a drive to have multiple, that is the point.  Just the same as if a drive supported both an NVME-mi interface AND a TMP75."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> Just the same as if a drive supported both an NVME-mi interface AND a TMP75.\n\nThe NVME-mi and TMP75 works on different physical protocol. I am thinking a different scenario: a device supporting multiple MCTP types (NVMe, PLDM, etc). I am not sure if there is such a device in practise. But if so, configuration of NVME1000 and PLDM will trigger both daemons(NVMe, PLDM) to initialize the same MCTP ep on MCTPd. \n\nIt seems to be OK on a second thought. The daemon can probe the MCTPd and do a MCTPLearn() before ep initialization."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 118,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> > Just the same as if a drive supported both an NVME-mi interface AND a TMP75.\n> \n> The NVME-mi and TMP75 works on different physical protocol. I am thinking a different scenario: a device supporting multiple MCTP types (NVMe, PLDM, etc). I am not sure if there is such a device in practise.\n> But if so, configuration of NVME1000 and PLDM will trigger both daemons(NVMe, PLDM) to initialize the same MCTP ep on MCTPd.\n> \n> It seems to be OK on a second thought. The daemon can probe the MCTPd and do a MCTPLearn() before ep initialization.\n\n\nYep, you got it."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "It's not clear why having these very-specific interfaces on dbus is helpful, given the requirements you've laid out.  These are arguably implementation details of the nvme subsystem, and for the most part, should probably be abstracted away from dbus.  I could see possibly wanting to expose the controllers to add a \"manager\" resource within Redfish, but that probably deserves a design doc on its own."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "MI CMD set works at the subsystem scope but the Admin CMD set needs to be attached to the controllers. LogPages are independent across controllers too. \n\nWe also want to expose the Physical Function-Virtual Function relation since they include a different set of vendor defined commands. The VU cmd is not discussed in this doc but we need to prepare for it."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> MI CMD set works at the subsystem scope but the Admin CMD set needs to be attached to the controllers. LogPages are independent across controllers too. \n\nWhy does any of this need to be exposed to dbus?  Generally we wouldn't implement a \"raw\" nvme-mi command on dbus, and instead would expose the relavant sensors, inventory items, and other things.\n\n> \n> We also want to expose the Physical Function-Virtual Function relation since they include a different set of vendor defined commands. The VU cmd is not discussed in this doc but we need to prepare for it.\n\nI'm not sure why this changes anything.  Vendor defined commands can be put in the same daemon, same as we do with things like IPMBSensor."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> Why does any of this need to be exposed to dbus?  Generally we wouldn't implement a \"raw\" nvme-mi command on dbus, and instead would expose the relavant sensors, inventory items, and other things.\n\nUnderstand that we are trying not to expose the protocol on DBus. The problem is it is hard to map all NVMe structure/attributes/method to a DBus sensor interface. Swordfish is inventing a lot of new schemas stressing NVMe, but there is still quite behind our need (Get/Set Features, Security Send/Recv, and many other attributes). We are pushing the DMTF, but until that perfect world, we still need raw NVMe interface on DBus for these not-scoped information. \n\nI doubt whether we want to go alone the way of transplanting NVMe on DBus sensors even with a complete Swordfish define. The current mapping guide for swordfish is 300ish pages. We need a similar thing for DBus NVMe sensor. \n\nI have a feeling the BMCWeb is the place for the swordfish translation out of raw NVMe API. other generic NVMe sensors (such as the current thermal one) can build around the raw NVMe protocol daemon."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> > Why does any of this need to be exposed to dbus?  Generally we wouldn't implement a \"raw\" nvme-mi command on dbus, and instead would expose the relavant sensors, inventory items, and other things.\n> \n> Understand that we are trying not to expose the protocol on DBus. The problem is it is hard to map all NVMe structure/attributes/method to a DBus sensor interface.\n\nProbably going to disagree with \"hard\" here.  If we can get a list of the properties you want to expose, lets take a look to evaluate how hard this is.\n\n> Swordfish is inventing a lot of new schemas stressing NVMe, but there is still quite behind our need (Get/Set Features, Security Send/Recv, and many other attributes). We are pushing the DMTF, but until that perfect world, we still need raw NVMe interface on DBus for these not-scoped information. \n\nI'm failing to make the jump between \"DMTF doesn't have schemas\" and \"Therefore we need a raw dbus interface\".  Dbus can have a properly structured interface, and if someone wants to map that to non-redfish, they can.\n\n> \n> I doubt whether we want to go alone the way of transplanting NVMe on DBus sensors even with a complete Swordfish define.\n\nIt doesn't have to be \"complete\" but it can be incremental.\n\n> The current mapping guide for swordfish is 300ish pages. We need a similar thing for DBus NVMe sensor. \n\nWhat mapping guide are you talking about?\n\n\n\n> \n> I have a feeling the BMCWeb is the place for the swordfish translation out of raw NVMe API.\n\n\nAs the bmcweb maintainer, definitely not.  bmcweb aspires to push business logic to other daemons to reduce its security scope, and decrease the likelihood of a bug taking down the whole OOB interface.  What you're suggesting is essentially in direct opposition.  Swordfish schemas should definitely go in bmcweb, but we should be doing NVMe-MI -> Dbus -> Redfish, not NVMe-MI -> Redfish.\n\n> other generic NVMe sensors (such as the current thermal one) can build around the raw NVMe protocol daemon.\n\nThis breaks the principal of one daemon per interface;  Also, if this is your plan, can you please include it in your design doc?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> > > Why does any of this need to be exposed to dbus?  Generally we wouldn't implement a \"raw\" nvme-mi command on dbus, and instead would expose the relavant sensors, inventory items, and other things.\n> > \n> > Understand that we are trying not to expose the protocol on DBus. The problem is it is hard to map all NVMe structure/attributes/method to a DBus sensor interface.\n> \n> Probably going to disagree with \"hard\" here.  If we can get a list of the properties you want to expose, lets take a look to evaluate how hard this is.\n> \n\nSure. I will put a list of matrix we need for the stage 1. \n\n> > Swordfish is inventing a lot of new schemas stressing NVMe, but there is still quite behind our need (Get/Set Features, Security Send/Recv, and many other attributes). We are pushing the DMTF, but until that perfect world, we still need raw NVMe interface on DBus for these not-scoped information. \n> \n> I'm failing to make the jump between \"DMTF doesn't have schemas\" and \"Therefore we need a raw dbus interface\".  Dbus can have a properly structured interface, and if someone wants to map that to non-redfish, they can.\n> \n\nYes. But that means the DBus need to define some NVMe interface beyond/before Swordfish. The may fork the Swordfish/dbus definition path. To the contrast, raw NVMe API is also the golden standard. \n\n> > \n> > I doubt whether we want to go alone the way of transplanting NVMe on DBus sensors even with a complete Swordfish define.\n> \n> It doesn't have to be \"complete\" but it can be incremental.\n> \n> > The current mapping guide for swordfish is 300ish pages. We need a similar thing for DBus NVMe sensor. \n> \n> What mapping guide are you talking about?\n> \n> \n> \n> > \n> > I have a feeling the BMCWeb is the place for the swordfish translation out of raw NVMe API.\n> \n> \n> As the bmcweb maintainer, definitely not.  bmcweb aspires to push business logic to other daemons to reduce its security scope, and decrease the likelihood of a bug taking down the whole OOB interface.  What you're suggesting is essentially in direct opposition.  Swordfish schemas should definitely go in bmcweb, but we should be doing NVMe-MI -> Dbus -> Redfish, not NVMe-MI -> Redfish.\n\nFully understand the concern from BMCWeb maintenance. There is still a daemon behind BMCWeb to talk with. It is not proposed to let BMCWeb directly link to driver library. The argument is to attach a NVMe spec styled DBus interface to the daemon.\n\nI am trying to make the BMCWeb logic as simple as possible, tunneling the GET/PUT into NVMe DWORD read, write. The parsing/mapping is definitely an extra work on BMCWeb. But all other logic (initialization, association, caching, etc) should be done in the nvme daemon. \n\n> \n> > other generic NVMe sensors (such as the current thermal one) can build around the raw NVMe protocol daemon.\n> \n> This breaks the principal of one daemon per interface;  Also, if this is your plan, can you please include it in your design doc?\n\nThe relationship of NVMe (thermal) sensor and NVMed will be like ipmb sensor and ipmbd. \n\nI can definitely include that in the design doc."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> \n> The relationship of NVMe (thermal) sensor and NVMed will be like ipmb sensor and ipmbd. \n> \n\nA quick history less on how ipmb was built, and why we did that design.\n\nAt the time that was done, there was no in-kernel ipmb interface, so the ipmbd was created to store the locking between the various entities within the bmc when they tried to access in parallel and maintain the queues.\n\nIn the years after Dawid originaly built ipmbd, the ipmb driver was put into the kernel, which could maintain all that shared locking in within the driver model (which architecturally is a better place to put it).\n\nipmb was then ported to use the in-kernel model, because it was a simple patch, and made it incrementally better without breaking anyone.  Architecturally these days, it doesn't need to exist, and could easily be rolled out, with daemons like ipmbsensor directly talking to the ipmb driver.\n\nmctp is already in the kernel (we did it this way on purpose), which means comparing it to ipmb isn't really a good reason to make a dedicated daemon."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 131,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Thanks for the history lesson :) \n\nI come to realize that ipmbd is not a good example arguing about the necessity of nvmed."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 143,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "I suspect this should be \"enumerating\""
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 143,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Ack"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This is a pretty generalized anti-pattern that we found when writing the other nvme daemons, as well as the generalized dbus-sensors architecture.  Keeping the polling as close to the hardware as can, and relying on dbus eventing for the rest allows use cases like EventService to function, and leads to faster responding user APIs.  It would help a lot if you could enumerate _why_ you think you need this, and we can talk through the use cases, but there have been plenty of examples where we built things as you describe above, and had to rewrite them later to go to user-space polling."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I listed the reasons against local polling in the alternative section. \n\ntl;dr: \nThe NVMe OOB doesn't support async event and we need high level DC service to poll in order to reduce interference."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> The NVMe OOB doesn't support async event \n\nThe existing daemon does support async eventing from the kernel. (and took a lot of architecture work to do it)."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I may be wrong but I am not sure whether we are talking about the same. Async Event Request is prohibited on OOB mechanism(Figure 114. NVMe MI spec rev 1.2). \n\nWe prefer the upper layer SW (outside BMC) to perform active request model instead of BMC local polling, It benefit the coordination between inband and oob nvme transaction."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Yes, we were talking about different things.  Maybe make it more clear that runtime status is coming from the host?  I'm not sure I fully understand in this case."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I mean the NVMe OOB controller has no mechanism to push the status change to host software (ie. the bmc and upper layer DC SW). \n\nSo it is about who pulls the info, either BMC local polling or DC SW polling. We do the latter one because: \n1. The DC SW will coordinate with other DC service, such as FW updater, user management, clean up service and repair service about when to operate NVMe OOB. These services definitely outside the scope of NVMed and maybe outside BMC. \n2. The OOB may/will interfere with Inband transaction. We haven't evaluated the impact but the concern is in the NVMe Spec. We are certainly trying to avoid reading a large status table out of NVMe-MI while a heavy NVMe I/O task."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> I mean the NVMe OOB controller has no mechanism to push the status change to host software (ie. the bmc and upper layer DC SW). \n\n\nI thought there were status bits that we could poll rapidly in nvme, but sure, I understand your meaning now.\n\n> \n> So it is about who pulls the info, either BMC local polling or DC SW polling. We do the latter one because: \n> 1. The DC SW will coordinate with other DC service, such as FW updater, user management, clean up service and repair service about when to operate NVMe OOB. These services definitely outside the scope of NVMed and maybe outside BMC. \n\nTotally fine, and nothing I was concerned about would prevent that\n\n> 2. The OOB may/will interfere with Inband transaction.\n> We haven't evaluated the impact but the concern is in the NVMe Spec. We are certainly trying to avoid reading a large status table out of NVMe-MI while a heavy NVMe I/O task.\n\n\nAccording to the NVMe spec it shouldn't I thought?  They are separate channels.  Certainly not the interfaces that are expected to be polled, like thermal sensors and log pages.  Is there something in the spec you're looking at that makes you think otherwise?  Can you give me a section number?\n\n> We are certainly trying to avoid reading a large status table out of NVMe-MI while a heavy NVMe I/O task.\n\nThe log pages have a polling mechanism, and the drives I've worked with from major vendors in the past have accounted for this kind of thing in their software design, I'd be really surprised if there were drives that didn't."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> > I mean the NVMe OOB controller has no mechanism to push the status change to host software (ie. the bmc and upper layer DC SW). \n> \n> \n> I thought there were status bits that we could poll rapidly in nvme, but sure, I understand your meaning now.\n> \n> > \n> > So it is about who pulls the info, either BMC local polling or DC SW polling. We do the latter one because: \n> > 1. The DC SW will coordinate with other DC service, such as FW updater, user management, clean up service and repair service about when to operate NVMe OOB. These services definitely outside the scope of NVMed and maybe outside BMC. \n> \n> Totally fine, and nothing I was concerned about would prevent that\n\nOk. The sensor update will be trigger both internally and externally, depends on the attribute spec. I don't think either it is the factor to not use sensor interface.\n\n> \n> > 2. The OOB may/will interfere with Inband transaction.\n> > We haven't evaluated the impact but the concern is in the NVMe Spec. We are certainly trying to avoid reading a large status table out of NVMe-MI while a heavy NVMe I/O task.\n> \n> \n> According to the NVMe spec it shouldn't I thought?  They are separate channels.  Certainly not the interfaces that are expected to be polled, like thermal sensors and log pages.  Is there something in the spec you're looking at that makes you think otherwise?  Can you give me a section number?\n> \n> > We are certainly trying to avoid reading a large status table out of NVMe-MI while a heavy NVMe I/O task.\n> \n> The log pages have a polling mechanism, and the drives I've worked with from major vendors in the past have accounted for this kind of thing in their software design, I'd be really surprised if there were drives that didn't.\n\nYeah, we can read the same log table headers via the local poll and do the actual page payload when DC triggers that. \n\nWe have criteria on in-band/out-of-band/IO cross-performance, but still, in NVMe-MI spec v1.2 page 107: \n\n\"NVMe Admin Commands over the out-of-band mechanism may interfere with host software. A Management Controller should coordinate with the host or issue only NVMe Admin Commands that do not interfere with host software or in band NVMe commands (e.g., Identify).\""
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 145,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "PTAL at the new proposal"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Repeating again, all of the above is nvme-specific, and makes no attempt to reuse existing interfaces.  As-written, to accomplish your goals, this is going to require both IPMI and bmcweb to contain nvme-specific code about how to identify drives, read log pages, and do whatever else needs done.  I suspect this needs abstracted using the existing interfaces.  I suspect there's one or two interfaces that need added for the drive specific inventory things that we don't yet support, but as written, I don't think the above interfaces get us the level of abstraction on dbus that we generally would like to encourage."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Agree on the first half. We need to reuse/expose the general Drive/Storge (maybe StorageController and Volume) interface with generic properties/methods. \n\nBut there are still NVMe specific which is hard/impossible to be defined on DBus level (e.g NVMe Feature set and controller Identify info). so we still need a NVMe API on DBus."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "So make an xyz.openbmc_project.NVMeFeatureSet dbus interface and attach it to the drive?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> So make an xyz.openbmc_project.NVMeFeatureSet dbus interface and attach it to the drive?\n\nThere are more information polling from other NVMe CMD(Read NVMe-MI Data Structure, Identify, etc). Some of the information we need is: \n\n* Health status for the NVMe subsystem including warning(SW), temperature(CTMP), drive life(PDLU), contoller status(CCS).\n* Configuration for NVMe controller such as SMBus/I2C frequency and MCTP Transmission Unit Size.\n* Features for controllers involving Arbitration, Power Management, Controller Metadata, etc.\n* Identify information for controller and namespace, such as FW info, SN/MN, IEEE OUI Identifier(IEEE), Maximum Data Transfer Size(MDTS), RTD3 Resume Latency(RTD3R), RTD3 Entry Latency(RTD3E), etc\n\nSome of these information is storage generic but more is NVMe specific. \n\nThe point is, we try to avoid exhausting all definitions in NVMe spec and redo it on dbus. Swordfish does the mapping well (or trying to approach that). The new daemon should work as NVMe protocol daemon(like ipmbd?). The consumer services, such as BMCWeb, should do the protocol translation. BMCWeb has the schemas and the translation layer in our management node (outside BMC) has the protobuf for grpc/streamz."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> > So make an xyz.openbmc_project.NVMeFeatureSet dbus interface and attach it to the drive?\n> \n> There are more information polling from other NVMe CMD(Read NVMe-MI Data Structure, Identify, etc). Some of the information we need is: \n> \n> * Health status for the NVMe subsystem including warning(SW), \n\nStatus interfaces have been around for a while.\n\n>temperature(CTMP),\n\nSo.... this is duplicating temperature code?  This is sounding more and more like it needs to go in the existing daemon.\n\n> drive life(PDLU), contoller status(CCS).\n> * Configuration for NVMe controller such as SMBus/I2C frequency and MCTP Transmission Unit Size.\n\nThat kind of data shouldn't be on dbus (probably).  Those are arguably internal system details of the communication channel that should be abstracted away from dbus.\n\n> * Features for controllers involving Arbitration, Power Management, Controller Metadata, etc.\n\nWhy is this information required outside the daemon itself that's talking to the controller?  Wouldn't this just get exposed as normal reset interfaces?\n\n> * Identify information for controller and namespace, such as FW info, SN/MN, IEEE OUI Identifier(IEEE), Maximum Data Transfer Size(MDTS), RTD3 Resume Latency(RTD3R), RTD3 Entry Latency(RTD3E), etc\n\nMost of these likely map into the Asset interfaces.  For the ones that don't, we can add new interfaces.\n\n> \n> Some of these information is storage generic but more is NVMe specific. \n\n> \n> The point is, we try to avoid exhausting all definitions in NVMe spec and redo it on dbus.\n\nUnfortunately, that just means that we get to duplicate all the definitions in bmcweb/redfish/ipmi.  As a system-level design, we try to avoid that.\n\n> Swordfish does the mapping well (or trying to approach that). The new daemon should work as NVMe protocol daemon(like ipmbd?). The consumer services, such as BMCWeb, should do the protocol translation. BMCWeb has the schemas and the translation layer \n\nbmcweb translates dbus->redfish, and we try to keep as much business logic out ofit that we can to keep a small footprint, and to spread out the security consequences and failure modes.  Redfish very intentionally doesn't allow \"transports\" like this.\n\n>in our management node (outside BMC) has the protobuf for grpc/streamz."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> > > So make an xyz.openbmc_project.NVMeFeatureSet dbus interface and attach it to the drive?\n> > \n> > There are more information polling from other NVMe CMD(Read NVMe-MI Data Structure, Identify, etc). Some of the information we need is: \n> > \n> > * Health status for the NVMe subsystem including warning(SW), \n> \n> Status interfaces have been around for a while.\n\nYes, the every storage protocol has a SMART-like info. So this part can be generic. \n\n> \n> >temperature(CTMP),\n> \n> So.... this is duplicating temperature code?  This is sounding more and more like it needs to go in the existing daemon.\n> \n\nYes. There are two thermal reporting path. The pid service internally will work on the NVMe thermal sensor for NVMe subsystem. The DC need extra thermal info for each NVMe controller through NVMe SMART Health Log Page, which will report by NVMed->redfish->DC SW\n\n> > drive life(PDLU), contoller status(CCS).\n> > * Configuration for NVMe controller such as SMBus/I2C frequency and MCTP Transmission Unit Size.\n> \n> That kind of data shouldn't be on dbus (probably).  Those are arguably internal system details of the communication channel that should be abstracted away from dbus.\n> \n> > * Features for controllers involving Arbitration, Power Management, Controller Metadata, etc.\n> \n> Why is this information required outside the daemon itself that's talking to the controller?  Wouldn't this just get exposed as normal reset interfaces?\n> \n\nThe reason is currently out the the control of BMC. The DC SW will ask the BMC to report the matrix and extract the information they like. I will talk to the DC SW team for the specific attributes, but the first answer I got from them was \"that will be a long list\". \n\n\n> > * Identify information for controller and namespace, such as FW info, SN/MN, IEEE OUI Identifier(IEEE), Maximum Data Transfer Size(MDTS), RTD3 Resume Latency(RTD3R), RTD3 Entry Latency(RTD3E), etc\n> \n> Most of these likely map into the Asset interfaces.  For the ones that don't, we can add new interfaces.\n> \n\nThey could be but they need to be part of StorageController. \nAnyway, I will make a list of the specific matrix so we can start from there. \n\n> > \n> > Some of these information is storage generic but more is NVMe specific. \n> \n> > \n> > The point is, we try to avoid exhausting all definitions in NVMe spec and redo it on dbus.\n> \n> Unfortunately, that just means that we get to duplicate all the definitions in bmcweb/redfish/ipmi.  As a system-level design, we try to avoid that.\n\nSorry, I didn't get that. Why it will cause a duplication in bmcweb/redfish/ipmi? Actually the reason we create a NVMe raw interface on DBus is to avoid duplicating the definition. \n\nThe reasoning here is that the NVMe information can be parsed at different levels. The generic storage info can be parse at daemon level for ipmi/redfish part of BMCWeb. The Swordfish of BMCWeb can parse the NVMe specific information from the DBus NVMe raw interface. The DCSW can parse rest of the unscoped NVMe-MI and NVMe-MI VUC. \n\n> \n> > Swordfish does the mapping well (or trying to approach that). The new daemon should work as NVMe protocol daemon(like ipmbd?). The consumer services, such as BMCWeb, should do the protocol translation. BMCWeb has the schemas and the translation layer \n> \n> bmcweb translates dbus->redfish, and we try to keep as much business logic out ofit that we can to keep a small footprint, and to spread out the security consequences and failure modes.  Redfish very intentionally doesn't allow \"transports\" like this.\n> \n\nCopied from the other commit: \n\nFully understand the concern from BMCWeb maintenance. There is still a daemon behind BMCWeb to talk with. It is not proposed to let BMCWeb directly link to driver library. The argument is to attach a NVMe spec styled DBus interface to the daemon.\n\nI am trying to make the BMCWeb logic as simple as possible, tunneling the GET/PUT into NVMe DWORD read, write. The parsing/mapping is definitely an extra work on BMCWeb. But all other logic (initialization, association, caching, etc) should be done in the nvme daemon. \n\n> >in our management node (outside BMC) has the protobuf for grpc/streamz."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> > > > So make an xyz.openbmc_project.NVMeFeatureSet dbus interface and attach it to the drive?\n> > > \n> > > There are more information polling from other NVMe CMD(Read NVMe-MI Data Structure, Identify, etc). Some of the information we need is: \n> > > \n> > > * Health status for the NVMe subsystem including warning(SW), \n> > \n> > Status interfaces have been around for a while.\n> \n> Yes, the every storage protocol has a SMART-like info. So this part can be generic. \n> \n> > \n> > >temperature(CTMP),\n> > \n> > So.... this is duplicating temperature code?  This is sounding more and more like it needs to go in the existing daemon.\n> > \n> \n> Yes. There are two thermal reporting path.\n> The pid service internally will work on the NVMe thermal sensor for NVMe subsystem.\n> The DC need extra thermal info for each NVMe controller through NVMe SMART Health Log Page, which will report by NVMed->redfish->DC SW\n\nI don't think this works in the design.  This will\n\n1. Duplicate state on dbus\n2. Duplicate code in the backend.\n\nNeither of which I'm interested in maintaining.\n\n> \n> > > drive life(PDLU), contoller status(CCS).\n> > > * Configuration for NVMe controller such as SMBus/I2C frequency and MCTP Transmission Unit Size.\n> > \n> > That kind of data shouldn't be on dbus (probably).  Those are arguably internal system details of the communication channel that should be abstracted away from dbus.\n> > \n> > > * Features for controllers involving Arbitration, Power Management, Controller Metadata, etc.\n> > \n> > Why is this information required outside the daemon itself that's talking to the controller?  Wouldn't this just get exposed as normal reset interfaces?\n> > \n> \n> The reason is currently out the the control of BMC.\n\nIf it's out of control of the bmc, then it's going through an OOB interface, (based on your doc Redfish).  Redfish requires well structured data.\n\n> The DC SW will ask the BMC to report the matrix and extract the information they like. I will talk to the DC SW team for the specific attributes, but the first answer I got from them was \"that will be a long list\".\n\nGreat.  Lets get that list and go from there.\n\n> \n> \n> > > * Identify information for controller and namespace, such as FW info, SN/MN, IEEE OUI Identifier(IEEE), Maximum Data Transfer Size(MDTS), RTD3 Resume Latency(RTD3R), RTD3 Entry Latency(RTD3E), etc\n> > \n> > Most of these likely map into the Asset interfaces.  For the ones that don't, we can add new interfaces.\n> > \n> \n> They could be but they need to be part of StorageController.\n\nThat's not a problem.  Asset is used in a number of places, StorageController will just be one more\n\n> Anyway, I will make a list of the specific matrix so we can start from there. \n> \n> > > \n> > > Some of these information is storage generic but more is NVMe specific. \n> > \n> > > \n> > > The point is, we try to avoid exhausting all definitions in NVMe spec and redo it on dbus.\n> > \n> > Unfortunately, that just means that we get to duplicate all the definitions in bmcweb/redfish/ipmi.  As a system-level design, we try to avoid that.\n> \n> Sorry, I didn't get that. Why it will cause a duplication in bmcweb/redfish/ipmi? Actually the reason we create a NVMe raw interface on DBus is to avoid duplicating the definition. \n\nWhen bmcweb wants to get a temperature reading, or a log page, it will need to \"speak\" nvme protocol on dbus.  This requires data structures that know how to package an nvme request, and interpret an nvme response.\n\nIf I now want that same data on IPMI, which maybe you don't want, but I'm sure others do, now IPMI has to copy those same data structures over.  We avoid this by putting well formed and reasonable abstractions on dbus.\n\n> \n> The reasoning here is that the NVMe information can be parsed at different levels.\n\nTo be clear, we have a mechanism for parsing log pages and putting them on dbus.  That's reasonable and there's prior interfaces for that.\n\n> The generic storage info can be parse at daemon level for ipmi/redfish part of BMCWeb. The Swordfish of BMCWeb can parse the NVMe specific information from the DBus NVMe raw interface.\n\nbmcweb knows how to parse well structured dbus interfaces, like sensors and logs.  Once those are mapped, we can discuss how to handle other stuff, including if you want some kind of \"raw nvme socket\" like we have for serial or something, but it's not going to fit in well formed redfish payloads.\n\n> The DCSW can parse rest of the unscoped NVMe-MI and NVMe-MI VUC. \n\nPlease talk about how this would work at an interfacing level.\n\n> \n> > \n> > > Swordfish does the mapping well (or trying to approach that). The new daemon should work as NVMe protocol daemon(like ipmbd?). The consumer services, such as BMCWeb, should do the protocol translation. BMCWeb has the schemas and the translation layer \n> > \n> > bmcweb translates dbus->redfish, and we try to keep as much business logic out ofit that we can to keep a small footprint, and to spread out the security consequences and failure modes.  Redfish very intentionally doesn't allow \"transports\" like this.\n> > \n> \n> Copied from the other commit: \n> \n> Fully understand the concern from BMCWeb maintenance. There is still a daemon behind BMCWeb to talk with. It is not proposed to let BMCWeb directly link to driver library.\n>The argument is to attach a NVMe spec styled DBus interface to the daemon.\n\nThe linking is one concern, needing to parse, construct, and interpret NVMe messages on dbus is a much bigger concern.\n\n> \n> I am trying to make the BMCWeb logic as simple as possible, tunneling the GET/PUT into NVMe DWORD read, write.\n\nSo, you're not using redfish then?  Redfish definitely doesn't give a \"DWORD Write\" interface, and has very explicitly rejected it at a standards level many times.  I'm in the DMTF meetings every week if you'd like to open a thread and start that discussion again.\n\n> The parsing/mapping is definitely an extra work on BMCWeb.\n\nand IPMI.  And PLDM.   More importantly, we have patterns in the project that avoid this extra work and we should use them.\n\n> But all other logic (initialization, association, caching, etc) should be done in the nvme daemon.\n> \n> > >in our management node (outside BMC) has the protobuf for grpc/streamz."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 179,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> > > > > So make an xyz.openbmc_project.NVMeFeatureSet dbus interface and attach it to the drive?\n> > > > \n> > > > There are more information polling from other NVMe CMD(Read NVMe-MI Data Structure, Identify, etc). Some of the information we need is: \n> > > > \n> > > > * Health status for the NVMe subsystem including warning(SW), \n> > > \n> > > Status interfaces have been around for a while.\n> > \n> > Yes, the every storage protocol has a SMART-like info. So this part can be generic. \n> > \n> > > \n> > > >temperature(CTMP),\n> > > \n> > > So.... this is duplicating temperature code?  This is sounding more and more like it needs to go in the existing daemon.\n> > > \n> > \n> > Yes. There are two thermal reporting path.\n> > The pid service internally will work on the NVMe thermal sensor for NVMe subsystem.\n> > The DC need extra thermal info for each NVMe controller through NVMe SMART Health Log Page, which will report by NVMed->redfish->DC SW\n> \n> I don't think this works in the design.  This will\n> \n> 1. Duplicate state on dbus\n> 2. Duplicate code in the backend.\n> \n> Neither of which I'm interested in maintaining.\n\nAs we plan to the direction of nvme sensor, there will not duplicate daemons on the same machine. It will be either a nvme basic cmd sensor(the original nvme sensor), or a nvme-mi thermal sensor. \n\nBTW, nvme-mi does support reporting thermal per controller, a nvme subsys might report multiple thermal sensor objects. \n\n> \n> > \n> > > > drive life(PDLU), contoller status(CCS).\n> > > > * Configuration for NVMe controller such as SMBus/I2C frequency and MCTP Transmission Unit Size.\n> > > \n> > > That kind of data shouldn't be on dbus (probably).  Those are arguably internal system details of the communication channel that should be abstracted away from dbus.\n> > > \n> > > > * Features for controllers involving Arbitration, Power Management, Controller Metadata, etc.\n> > > \n> > > Why is this information required outside the daemon itself that's talking to the controller?  Wouldn't this just get exposed as normal reset interfaces?\n> > > \n> > \n> > The reason is currently out the the control of BMC.\n> \n> If it's out of control of the bmc, then it's going through an OOB interface, (based on your doc Redfish).  Redfish requires well structured data.\n> \n\nAgreed that data via Redfish should be structured. These none-scoped attributes should transport outside Redfish (Maybe google domain)\n\n> > The DC SW will ask the BMC to report the matrix and extract the information they like. I will talk to the DC SW team for the specific attributes, but the first answer I got from them was \"that will be a long list\".\n> \n> Great.  Lets get that list and go from there.\n\nWill list together will the proposing nvme sensor interface. \n> \n> > \n> > \n> > > > * Identify information for controller and namespace, such as FW info, SN/MN, IEEE OUI Identifier(IEEE), Maximum Data Transfer Size(MDTS), RTD3 Resume Latency(RTD3R), RTD3 Entry Latency(RTD3E), etc\n> > > \n> > > Most of these likely map into the Asset interfaces.  For the ones that don't, we can add new interfaces.\n> > > \n> > \n> > They could be but they need to be part of StorageController.\n> \n> That's not a problem.  Asset is used in a number of places, StorageController will just be one more\n> \n> > Anyway, I will make a list of the specific matrix so we can start from there. \n> > \n> > > > \n> > > > Some of these information is storage generic but more is NVMe specific. \n> > > \n> > > > \n> > > > The point is, we try to avoid exhausting all definitions in NVMe spec and redo it on dbus.\n> > > \n> > > Unfortunately, that just means that we get to duplicate all the definitions in bmcweb/redfish/ipmi.  As a system-level design, we try to avoid that.\n> > \n> > Sorry, I didn't get that. Why it will cause a duplication in bmcweb/redfish/ipmi? Actually the reason we create a NVMe raw interface on DBus is to avoid duplicating the definition. \n> \n> When bmcweb wants to get a temperature reading, or a log page, it will need to \"speak\" nvme protocol on dbus.  This requires data structures that know how to package an nvme request, and interpret an nvme response.\n> \n> If I now want that same data on IPMI, which maybe you don't want, but I'm sure others do, now IPMI has to copy those same data structures over.  We avoid this by putting well formed and reasonable abstractions on dbus.\n\nWe will have these \"famous\" interfaces exposed in the general way (value and threshold) so it wouldn't re-interpret across BMCWeb and ipmid. \n\nBut there are still NVMe specific DBus interface that aiming at Swordfish (even not embraced by the original Redfish). I don't think impi will bother these. \n \n> \n> > \n> > The reasoning here is that the NVMe information can be parsed at different levels.\n> \n> To be clear, we have a mechanism for parsing log pages and putting them on dbus.  That's reasonable and there's prior interfaces for that.\n> \n> > The generic storage info can be parse at daemon level for ipmi/redfish part of BMCWeb. The Swordfish of BMCWeb can parse the NVMe specific information from the DBus NVMe raw interface.\n> \n> bmcweb knows how to parse well structured dbus interfaces, like sensors and logs.  Once those are mapped, we can discuss how to handle other stuff, including if you want some kind of \"raw nvme socket\" like we have for serial or something, but it's not going to fit in well formed redfish payloads.\n\nAgree with every statement here. It is not appropriate to transferring un-parsed raw stream over the Redfish. \n\nBut BMCWeb should not be constrained to that limitation. It should be able to packing streams over the http protocol. \n\n> \n> > The DCSW can parse rest of the unscoped NVMe-MI and NVMe-MI VUC. \n> \n> Please talk about how this would work at an interfacing level.\n> \n> > \n> > > \n> > > > Swordfish does the mapping well (or trying to approach that). The new daemon should work as NVMe protocol daemon(like ipmbd?). The consumer services, such as BMCWeb, should do the protocol translation. BMCWeb has the schemas and the translation layer \n> > > \n> > > bmcweb translates dbus->redfish, and we try to keep as much business logic out ofit that we can to keep a small footprint, and to spread out the security consequences and failure modes.  Redfish very intentionally doesn't allow \"transports\" like this.\n> > > \n> > \n> > Copied from the other commit: \n> > \n> > Fully understand the concern from BMCWeb maintenance. There is still a daemon behind BMCWeb to talk with. It is not proposed to let BMCWeb directly link to driver library.\n> >The argument is to attach a NVMe spec styled DBus interface to the daemon.\n> \n> The linking is one concern, needing to parse, construct, and interpret NVMe messages on dbus is a much bigger concern.\n> \n> > \n> > I am trying to make the BMCWeb logic as simple as possible, tunneling the GET/PUT into NVMe DWORD read, write.\n> \n> So, you're not using redfish then?  Redfish definitely doesn't give a \"DWORD Write\" interface, and has very explicitly rejected it at a standards level many times.  I'm in the DMTF meetings every week if you'd like to open a thread and start that discussion again.\n> \n> > The parsing/mapping is definitely an extra work on BMCWeb.\n> \n> and IPMI.  And PLDM.   More importantly, we have patterns in the project that avoid this extra work and we should use them.\n> \n> > But all other logic (initialization, association, caching, etc) should be done in the nvme daemon.\n> > \n> > > >in our management node (outside BMC) has the protobuf for grpc/streamz.\n\nThe design for redfish part of the daemon has changed according to the discussion in this thread. We are going to have parsed data on DBus for Redfish."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 187,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This isn't in your requirements."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 187,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Sorry, I miss the anchor for this comment. But please point out if you still have the same disagreement on the updated version."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 191,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Can you rephrase this, I'm not quite understanding this."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 191,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "The design is reworked."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 196,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Other impacts:\n1. Physical layer constructs are now present in dbus, which very likely has security impacts.\n2. nvme-specific is now spread across the system\n3. A third nvme-specific daemon is created."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 196,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "The design is totally rework. \n\n> Other impacts:\n> 1. Physical layer constructs are now present in dbus, which very likely has security impacts.\n\nOnly telemetry reading protocol API are exposed now. and none of them are security operation such as format/santize/namespace deletion, there should be no security impact on current BMC system. \n\n> 2. nvme-specific is now spread across the system\n\nOnly limit NVMe spec is exposed and they will be eliminated after the inband to oob migration is completed. \n \n> 3. A third nvme-specific daemon is created.\nthe proposed daemon will merge with nvme sensor."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 200,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Okay, can you please add some more words justifying why they're complementary but must be separate? Am I just not across enough of the design points of phosphor-nvme? If not, can you please make sure that people like me reading this document can be convinced of your position just by reading the document (and any references)?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 200,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> Okay, can you please add some more words justifying why they're complementary but must be separate?\n> Am I just not across enough of the design points of phosphor-nvme? If not, can you please make sure that people like me reading this document can be convinced of your position just by reading the document (and any references)?\n\n+1, I'd really like to understand this point as well.  It's not clear from the above."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 200,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Now the nvme sensor should merge into the proposed daemon. It would also consider move the merged daemon out of sensor repo. \n\nPTAL the reason I argued in the updated design doc."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 205,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Load testing?  Security testing?  Functional testing?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 205,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "The function test will be the first step, but I am also thinking about the performance on I2c and Dbus when doing the implementation. \n\nPTAL at the updated plan."
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 205,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 218,
            "sizeDeletions": 0
        },
        {
            "number": 2,
            "revision": "e7d7e4a9239de3a94711f1b55a3c1b292fc791d1",
            "parents": [
                "9915e5d21d3009eab284b321fef46f9301a13206"
            ],
            "ref": "refs/changes/09/53809/2",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1657665422,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Hao, can you please wrap all the lines so the document is more easily read?"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "One thing I didn't realize is that arj had completely removed the MCTP stuff from the existing nvme daemon.  That weakens my argument a little, but considering both protocols are:\n1. Targeting the same specification.\n2. Targeting the same devices (with nvme-basic being possibly optional)\n3. Likely exposing the same interfaces.\n\nI still think it makes sense for them to be in the same daemon implementation.  To be clear, I don't have a need to maintain it (although I'll continue if I have to), and nvme-sensor doesn't have to stay in dbus-sensors, but there are a number of things that I don't think we should step backwards on, and there are other people that use the existing code, of which there isn't much code for nvme-sensor itself.  Moving it to wherever we decide put the new daemon and with whatever seasoned maintainer wants to maintain it is fine with me if that's the result, but whomever it is needs to take over nvme as a whole (including the existing reactor) and not just start over from scratch unless there's a good coding architectural reason to do so.  (good reasons might include a different language, major changes to IO model, ect).  Wanting more features isn't a good reason IMO, those can always be added to the already maintained daemon, where we've worked through all the boilerplate, \"how to build a reactor\" stuff."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "Just doing a bit of a summary here, just to check that I'm on the same page with the discussions so far:\n\n> I still think it makes sense for them to be in the same daemon implementation.\n\nI definitely think that's reasonable, and we should get a little design overview for that approach.\n\nHao, correct me if I'm wrong, but at a rough overview: your goal here is expose functionality available from the management side of a NVMe device. The initial proposal is a fairly direct mapping of the NVMe-MI facilities to a dbus interface.\n\nSince then, it's become apparently that we really should be exposing these in a more general \"OpenBMC object model\"; for example, instead of exposing a NVM Subsystem Health Status Data Structure on d-bus, we should just be extracting the relevant bits out of that (composite temperature, drive life used, etc), as regular OpenBMC sensors. That achieves a more \"BMC-like\" access to the MI data.\n\n[whether we still expose the NSHDS in addition to the actual sensors is another question perhaps...]\n\nWe also have a future set of requirements on more NVMe-specific (or at least storage-device-specific) functionality, like namespace/volume management, secure erase, etc. The direction here would be to support a Swordfish-standardised API for off-BMC management agents. This would allow the control that Hao is looking to provide for DC integration.\n\nFor that latter requirement, we'd be looking to expose the MI functions as closely as possible to the Redfish/Swordfish schema; this might be a shift from the existing proposal, where it's closer to the MI spec than the eventual REST API (ie, Swordfish) data layout.\n\nOverall though, it makes sense to have a single daemon for both of those requirements. To me, the design point of having one daemon as a single point of communication with the NVMe-MI endpoint is the important one here.\n\nWe could consider the NVMe-Basic and NVMe-MI protocols as separate endpoints, but there's probably enough overlap in the supporting infrastructure (VPD discovery etc) to warrant putting both into one codebase.\n\nTBH, I'm OK with either approach, as long as:\n\n- we have sensible representations of the core inventory/sensor data; and\n- adding the richer set of NVMe-MI control functionality doesn't mean we end up out-of-scope for a dbus-sensors component"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "> One thing I didn't realize is that arj had completely removed the MCTP stuff from the existing nvme daemon.  That weakens my argument a little\n\nHonestly, I think you're putting too much weight on me ripping out the MCTP support. I did that because it was unbuildable, and being unable to even build it prevented me from refactoring other parts of the code.\n\nTo be clear, I did not rip it out because I don't want to support MCTP in nvmesensor, I ripped it out because the _specific_ _implementation_ was unmaintainable.\n\nNow we have kernel support for MCTP and NVMe-MI support in libnvme, I see no reason not to add it back in.\n\nAs such, I don't think the current state of the code changes the argument at all.\n\n> I still think it makes sense for them to be in the same daemon implementation.  \n\nAs do I, and Jeremy too.\n\n> Wanting more features isn't a good reason IMO, those can always be added to the already maintained daemon, where we've worked through all the boilerplate, \"how to build a reactor\" stuff.\n\nPrecisely. I don't se any reason why we can't grow extra NVMe management features here. Calling the repo \"dbus-sensors\" was a mistake I think, in that it constrains peoples' understanding of its content to sensors. A better name is something like \"entity-reactors\" IMO."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> > One thing I didn't realize is that arj had completely removed the MCTP stuff from the existing nvme daemon.  That weakens my argument a little\n> \n> Honestly, I think you're putting too much weight on me ripping out the MCTP support. I did that because it was unbuildable, and being unable to even build it prevented me from refactoring other parts of the code.\n\nSure, maybe I overemphasized it, and I didn't mean to call you out directly if that's how you felt (you did the right thing).  I mostly did it to call out that I had made a mistake which had caused confusion in the design.  I think we're in agreement on the overall direction here regardless.\n\n> As do I, and Jeremy too.\n> \n> > Wanting more features isn't a good reason IMO, those can always be added to the already maintained daemon, where we've worked through all the boilerplate, \"how to build a reactor\" stuff.\n> \n> Precisely. I don't se any reason why we can't grow extra NVMe management features here. Calling the repo \"dbus-sensors\" was a mistake I think, in that it constrains peoples' understanding of its content to sensors. A better name is something like \"entity-reactors\" IMO.\n\nI've been meaning to propose changing it to dbus-reactors, but I kinda like your name better now that I think about it.  I should really get on that....\n\n\n\n\n\nAgree with everything in Jeremy's overview here.\n\n> we'd be looking to expose the MI functions as closely as possible to the Redfish/Swordfish schema\n\nFWIW, most of the phosphor-dbus-interfaces added in recent years have been \"redfish inspired\" in their wording and enum choices.  \"Redfish does it this way\" isn't a complete justification for most interface additions (we still have to apply dbus best practices and naming) but lots of interfaces have been added specifically to help redfish, so it's pretty doable to get stuff in to fulfill a well formed dbus interface."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "> > > One thing I didn't realize is that arj had completely removed the MCTP stuff from the existing nvme daemon.  That weakens my argument a little\n> > \n> > Honestly, I think you're putting too much weight on me ripping out the MCTP support. I did that because it was unbuildable, and being unable to even build it prevented me from refactoring other parts of the code.\n> \n> Sure, maybe I overemphasized it, and I didn't mean to call you out directly if that's how you felt (you did the right thing).  I mostly did it to call out that I had made a mistake which had caused confusion in the design.  I think we're in agreement on the overall direction here regardless.\n\nThanks for clarify the history of MCTP changes in nvme sensor. Yes, given the currently status of support on MCTP, we can recreate the thermal interface on top of the NVMe-MI spec in addition to NVMe basic command. \n  \n> \n> > As do I, and Jeremy too.\n> > \n> > > Wanting more features isn't a good reason IMO, those can always be added to the already maintained daemon, where we've worked through all the boilerplate, \"how to build a reactor\" stuff.\n> > \n> > Precisely. I don't se any reason why we can't grow extra NVMe management features here. Calling the repo \"dbus-sensors\" was a mistake I think, in that it constrains peoples' understanding of its content to sensors. A better name is something like \"entity-reactors\" IMO.\n> \n> I've been meaning to propose changing it to dbus-reactors, but I kinda like your name better now that I think about it.  I should really get on that....\n> \n> \nGiven the intention of nvme sensor(reactor) stated here, I think we can make consensus there, as Ed, Andrew, and Jeremy have suggested, to extend the current nvme sensor to support NVMe-MI functions. \n\nWe still need to decide the format of DBus interface through for all NVMe specifics. I will stress them in the modification of this doc. \n\n> \n> \n> \n> Agree with everything in Jeremy's overview here.\n> \n> > we'd be looking to expose the MI functions as closely as possible to the Redfish/Swordfish schema\n> \n> FWIW, most of the phosphor-dbus-interfaces added in recent years have been \"redfish inspired\" in their wording and enum choices.  \"Redfish does it this way\" isn't a complete justification for most interface additions (we still have to apply dbus best practices and naming) but lots of interfaces have been added specifically to help redfish, so it's pretty doable to get stuff in to fulfill a well formed dbus interface.\n\nWe also need to strike the none-redfish domain. As Redfish/Swordfish is still on its way updating the schemas and lack of some crucial components, we are going to rely on some NVMe raw data and routing to BMCWeb google root. The data path will be eliminated after the attributes/methods are accepted and published by DMTF Redfish."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Sure. Will do."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "PLAT at the new proposal."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 25,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "whitespace error."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 25,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Ack"
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 188,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 201,
            "sizeDeletions": 0
        },
        {
            "number": 3,
            "revision": "cc189cea42122be5c2b8c889651177964d73eb76",
            "parents": [
                "9915e5d21d3009eab284b321fef46f9301a13206"
            ],
            "ref": "refs/changes/09/53809/3",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1660176412,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I complete reword the design. The current will merge the functionality of NVMe sensor into the new design, and provide structured DBus interfaces. \n\nPTAL"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Looking much better.  I got to the inline html, then couldnt' really read it, but I can figure out a reader."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 39,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit This isn't really a list of requirements, this is a list of MCTP specification sections."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 39,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "NVMe specification you meant? But yeah, I will fix the sentence."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 55,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Generally we don't do inline HTML in our markdown.  Looking at it it just looks like this is a list?  Maybe just do\n\n- item 1\n- item 2\n\nto make it easier to review?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 55,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "+1"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 55,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Sure. I will turn the table into a bullet list."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 157,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit, \"north bound interface\" is generally the word we use for this."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 157,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Thanks for the correction. Will do the change."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 204,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit, this isn't a tunnel, maybe \"exposing Dbus Interfaces\""
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 204,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Received."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 216,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Like we talked about, I think we should start without any \"raw\" interface.  If this is present for debug or CLI use, that seems reasonable to have in a utils app, but shouldn't go on dbus."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 216,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "It is for production jobs. \n\nThis protocol interface fill in the gap between the current Swordfish definition and our requirement of NVMe spec. And it help the client (DCSW) to transit from inband to oob. \n\nWe have plan to migrate more telemetries from the NVMe spec into Swordfish in the coming projects. But given the current status of Swordfish and the timeline of the project at hand, it will be a blocker if we do not have the ability to expose these information. \n\nI had more statement in the \"NVMe Admin Interface\" section below. PTAL."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 216,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Isn't the way to deal with this in the OpenBMC project instead to not specify the raw interface in this document but to still implement it internally (at e.g. Google)? That way the project doesn't deal with the maintenance associated with use of the raw interface because as far as the project's concerned, it doesn't exist."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 225,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Can we make this more specific to \"NVMeProtocol\"?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 225,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Sure we can, but given the protocol is a member of a NVME1000 interface, doesn't it implicitly explain that is a NVMeProtocol?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 229,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "nit, please note this is the default."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 229,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Sure."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 230,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Camel case please."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 230,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "ACK."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 232,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "I don't think the design covers this yet?  I suspect it can probably be approved."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 232,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Yes, you are right. This proposal only focuses on mi_i2c, as I said at the end of this chapter. \n\nThe mi_vdm is used to align with the spec and reserved for future usage. We have a plan to support the MCTP over VDM to address transportation rate. \n\nBut of course, we can remove this type for now if you insist."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 244,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "We don't need an address here, given that the specification explicitly declares an address?  At the very least the defaults should be set to the specification required address."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 244,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "We do need to explicitly declare the address in configuration. The NVMe spec doesn't speak a default address for mctp controller. In fact, the system could have multiple nvme mctp controllers(subsystems) sitting on the same i2c bus. E.g. the expansion card case."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 251,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Because we expect this to be exposing more data, we need to a be a little careful of generic \"Thresholds\" terms, but admittedly, it's already too late for that.  just something to keep in mind."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 271,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Do we do inline html tables in other places?  It's a little tough to review in gerrit, but I can try to load it into a viewer if this is standard."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 271,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Yeah, there are a bunch of text tables here: https://raw.githubusercontent.com/openbmc/libmctp/master/docs/bindings/vendor-ibm-astlpc.md"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 271,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "I realized there is no md preview for gerrit. \n\nThe md basic table lacks the support for format within a cell. \n\nMaybe I can try to split the table to make it eaiser w/o html embedding? \n\nAny advice is welcome."
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 576,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 590,
            "sizeDeletions": 0
        },
        {
            "number": 4,
            "revision": "c1c294448c3718a9f78f5001257b7f5afbb2aafa",
            "parents": [
                "9915e5d21d3009eab284b321fef46f9301a13206"
            ],
            "ref": "refs/changes/09/53809/4",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1660249733,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "designs/nvmed.md",
                    "line": 504,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "What do we think of the statement? \n\nIs it better to stay inside phosphor-dbus-sensor, or worth a separate repo?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 504,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "Updated the statement here to make it more easy to understand."
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 524,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 538,
            "sizeDeletions": 0
        },
        {
            "number": 5,
            "revision": "628472ab74a0803ed7d726e6a95b00e0767790b9",
            "parents": [
                "9915e5d21d3009eab284b321fef46f9301a13206"
            ],
            "ref": "refs/changes/09/53809/5",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1660250656,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Hi Hao, thanks for continuing to chip away at this. I have a few comments."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 1,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Broadly, can we try to use formal language rather than informal? For example, currently \"DC\" is used without definition (I assume it means \"Data Centre\"), \"Config\" is used as a contraction for \"Configure\" etc. It's not a huge productivity impact to spell these out but it does improve readability."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 9,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Overall I think the problem description is summarised as \"NVMe management operations are being offloaded from the host to the BMC. OpenBMC does not yet support these management operations. We propose exposing the necessary management capabilities in OpenBMC\"?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 15,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "I'm guilty of this too, but the sentence is a bit of a monster. I think what it's trying to say is this?\n\n> However, for data centre use-cases, control of NVMe devices is being offloaded from the host to the BMC in order to reduce the impact of management tasks on host performance. BMCs communicate with the drives through the NVMe MI out-of-band interface."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 38,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Can we move the enumeration of these capabilities down into the requirements or background sections? I think the problem description should probably stay a bit more abstract than this."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 152,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Is this truly the case? Won't bmcweb be dealing with redfish/swordfish from the DBus representation, while the daemon translates NVMe-MI to DBus?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 152,
                    "reviewer": {
                        "name": "Jeremy Kerr",
                        "email": "jk@ozlabs.org",
                        "username": "jk-ozlabs"
                    },
                    "message": "The NVMe daemon's d-bus interface should be a fairly linear mapping of the redfish/swordfish models & interfaces; the daemon will be mapping these standard actions to their NVMe commands.\n\nThis means that the bmcweb implementation doesn't need to be aware of the NVMe command set."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 152,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Right, so I feel the description needs some light editing in that case."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 152,
                    "reviewer": {
                        "name": "Hao Jiang",
                        "email": "jianghao@google.com",
                        "username": "drakedog2008"
                    },
                    "message": "It is not only the mapping/translating problem, but also the scheduling. Only the nvmed will know when to poll the data from device."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 401,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Why are we trying to specify this upstream?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 402,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "incompatible?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 404,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "The way to do this is to not specify its existence to start with. I think you're free to implement such support downstream. That makes it a problem that you only need to justify internally, not to the upstream project, which will probably make it easier to get traction."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 405,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Mature?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 489,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "What does this mean? This is the first time I've seen it used in the document and it hasn't been defined."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 496,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Isn't exposing these capabilities an security concern in itself (availability/denial of service)?"
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 501,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "The repository is just called \"dbus-sensors\" FWIW."
                },
                {
                    "file": "designs/nvmed.md",
                    "line": 505,
                    "reviewer": {
                        "name": "Andrew Jeffery",
                        "email": "andrew@codeconstruct.com.au",
                        "username": "amboar"
                    },
                    "message": "Perhaps this would be clearer as \"out of dbus-sensors\""
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 525,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 539,
            "sizeDeletions": 0
        },
        {
            "number": 6,
            "revision": "10f2d00fbcfb97cfb02a1ee4005d82f237783668",
            "parents": [
                "9915e5d21d3009eab284b321fef46f9301a13206"
            ],
            "ref": "refs/changes/09/53809/6",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1665684498,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 551,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 565,
            "sizeDeletions": 0
        },
        {
            "number": 7,
            "revision": "e41abcac114aefe2770b1b99e1169104b56c139f",
            "parents": [
                "7b4a8a79ca08dfb8b88b0fca44e2090a76637283"
            ],
            "ref": "refs/changes/09/53809/7",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1697233025,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "TRIVIAL_REBASE",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 551,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 565,
            "sizeDeletions": 0
        },
        {
            "number": 8,
            "revision": "ff1a7ab97602698c9ebff12bcb1e686f20401966",
            "parents": [
                "7b4a8a79ca08dfb8b88b0fca44e2090a76637283"
            ],
            "ref": "refs/changes/09/53809/8",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1697233079,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 517,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 531,
            "sizeDeletions": 0
        },
        {
            "number": 9,
            "revision": "b70493a020d34aa5b49a76f5f30da2d46db6db14",
            "parents": [
                "7b4a8a79ca08dfb8b88b0fca44e2090a76637283"
            ],
            "ref": "refs/changes/09/53809/9",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1697233203,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 502,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 516,
            "sizeDeletions": 0
        },
        {
            "number": 10,
            "revision": "c10c337d7c2b1f7f4621c81db87a3cd19419b8fe",
            "parents": [
                "7b4a8a79ca08dfb8b88b0fca44e2090a76637283"
            ],
            "ref": "refs/changes/09/53809/10",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1697235006,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 495,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 509,
            "sizeDeletions": 0
        },
        {
            "number": 11,
            "revision": "5f70fa5ad51edf88d496d386d0b888e42e3b0e81",
            "parents": [
                "7b4a8a79ca08dfb8b88b0fca44e2090a76637283"
            ],
            "ref": "refs/changes/09/53809/11",
            "uploader": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "createdOn": 1697235116,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "NO_CHANGE",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 495,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 509,
            "sizeDeletions": 0
        },
        {
            "number": 12,
            "revision": "f4b7a86d84c21fe011cc37df330e91e02ac657e3",
            "parents": [
                "7b4a8a79ca08dfb8b88b0fca44e2090a76637283"
            ],
            "ref": "refs/changes/09/53809/12",
            "uploader": {
                "name": "Andrew Jeffery",
                "email": "andrew@codeconstruct.com.au",
                "username": "amboar"
            },
            "createdOn": 1697687318,
            "author": {
                "name": "Hao Jiang",
                "email": "jianghao@google.com",
                "username": "drakedog2008"
            },
            "kind": "REWORK",
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "designs/nvmed.md",
                    "type": "ADDED",
                    "insertions": 497,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 511,
            "sizeDeletions": 0
        }
    ]
}