{
    "project": "openbmc/phosphor-objmgr",
    "branch": "master",
    "id": "I902311c83623e6fdc7314dee21fe49149ccead17",
    "number": 53904,
    "subject": "[POC]: GetSubTreePaths: Throw when a path is in introspect",
    "owner": {
        "name": "Lei YU",
        "email": "yulei.sh@bytedance.com",
        "username": "mine260309"
    },
    "url": "https://gerrit.openbmc.org/c/openbmc/phosphor-objmgr/+/53904",
    "commitMessage": "[POC]: GetSubTreePaths: Throw when a path is in introspect\n\nWhen a path is doing introspect, the result is not complete, make\nGetSubTreePaths throw in such case to make sure only complete result\nare returned.\n\nOtherwise, the issue described in [1] will make mapper to return\nincorrect result.\n\nWith this patch, the caller could get an exception when the path is in\nintrospect and it could retry until it succeeds, to make sure the result\nis complete.\nThis is tested with 1000 logging entries + ipmid's SEL-cache feature,\nand it works as expected.\n\nNote this is POC and added only for GetSubTreePaths but not for\nGetSubTree, because in reality GetSubTree is used widely and it does\ncause several services crash during BMC boot.\n\n[1]: https://lore.kernel.org/openbmc/CAGm54UHU9s0bTq-AR9tJunoX2Wa9tQ0PH_zWJ2QrYdR3SRqcvg@mail.gmail.com/T/#u\n\nSigned-off-by: Lei YU <yulei.sh@bytedance.com>\nChange-Id: I902311c83623e6fdc7314dee21fe49149ccead17\n",
    "createdOn": 1653284245,
    "lastUpdated": 1654196207,
    "open": true,
    "status": "NEW",
    "comments": [
        {
            "timestamp": 1653284245,
            "reviewer": {
                "name": "Lei YU",
                "email": "yulei.sh@bytedance.com",
                "username": "mine260309"
            },
            "message": "Uploaded patch set 1."
        },
        {
            "timestamp": 1653284292,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 1: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1653284292,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 1: -Ok-To-Test"
        },
        {
            "timestamp": 1653285030,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 1: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-repository/43590/ : SUCCESS"
        },
        {
            "timestamp": 1653324954,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(2 comments)"
        },
        {
            "timestamp": 1653342526,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1653466927,
            "reviewer": {
                "name": "Lei YU",
                "email": "yulei.sh@bytedance.com",
                "username": "mine260309"
            },
            "message": "Patch Set 1:\n\n(3 comments)"
        },
        {
            "timestamp": 1653572714,
            "reviewer": {
                "name": "Matt Spinler",
                "email": "spinler@us.ibm.com",
                "username": "spinler"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1653589479,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1653593606,
            "reviewer": {
                "name": "Matt Spinler",
                "email": "spinler@us.ibm.com",
                "username": "spinler"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654016439,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654018483,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654019165,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654049847,
            "reviewer": {
                "name": "Brad Bishop",
                "email": "bradleyb@fuzziesquirrel.com",
                "username": "bradbishop"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654050116,
            "reviewer": {
                "name": "Lei YU",
                "email": "yulei.sh@bytedance.com",
                "username": "mine260309"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654050432,
            "reviewer": {
                "name": "Lei YU",
                "email": "yulei.sh@bytedance.com",
                "username": "mine260309"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654091567,
            "reviewer": {
                "name": "Matt Spinler",
                "email": "spinler@us.ibm.com",
                "username": "spinler"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654108448,
            "reviewer": {
                "name": "Brad Bishop",
                "email": "bradleyb@fuzziesquirrel.com",
                "username": "bradbishop"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654120722,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654121497,
            "reviewer": {
                "name": "Matt Spinler",
                "email": "spinler@us.ibm.com",
                "username": "spinler"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654121700,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(2 comments)"
        },
        {
            "timestamp": 1654123354,
            "reviewer": {
                "name": "Brad Bishop",
                "email": "bradleyb@fuzziesquirrel.com",
                "username": "bradbishop"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654128384,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654175285,
            "reviewer": {
                "name": "Matt Spinler",
                "email": "spinler@us.ibm.com",
                "username": "spinler"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654178225,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654180141,
            "reviewer": {
                "name": "Brad Bishop",
                "email": "bradleyb@fuzziesquirrel.com",
                "username": "bradbishop"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654188280,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654189918,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1654196207,
            "reviewer": {
                "name": "Matt Spinler",
                "email": "spinler@us.ibm.com",
                "username": "spinler"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        }
    ],
    "patchSets": [
        {
            "number": 1,
            "revision": "c804bff683b9ad7fd9743a638a94bc69ce5701f1",
            "parents": [
                "af3d797b011f3f0dfc6ad7eae44e5b312f5a3d6e"
            ],
            "ref": "refs/changes/04/53904/1",
            "uploader": {
                "name": "Lei YU",
                "email": "yulei.sh@bytedance.com",
                "username": "mine260309"
            },
            "createdOn": 1653284245,
            "author": {
                "name": "Lei YU",
                "email": "yulei.sh@bytedance.com",
                "username": "mine260309"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "/COMMIT_MSG",
                    "line": 11,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "As written, this is going to have LOTS of user-facing impacts if the mapper is no longer considered \"reliable\".  Doing this would mean that we need to add retries in every daemon (like bmcweb), which seems like a lot of complexity that I don't really want in those daemons.\n\nAs an alternative, what if the interfaces to be added were just added to the InProgressIntrospect object, then when that operation is completed, they would all be added to the global at one time, which I think would avoid your race condition?"
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 11,
                    "reviewer": {
                        "name": "Lei YU",
                        "email": "yulei.sh@bytedance.com",
                        "username": "mine260309"
                    },
                    "message": "> As written, this is going to have LOTS of user-facing impacts if the mapper is no longer considered \"reliable\". \n\nThis is true. I tried to add this logic in `GetSubTree` method and I did observe services like bmcweb get such exception during BMC startup.\nThat's why I only add this logic in `GetSubTreePaths` for now.\n\n> As an alternative, what if the interfaces to be added were just added to the InProgressIntrospect object, then when that operation is completed, they would all be added to the global at one time, which I think would avoid your race condition?\n\nI guess this is the pretty much the same as this patch. When it's in InProgressIntrospect and not available to the `GetSubTreePaths`, it will throw because getSubTreePaths() throws when there is no resource.\n\nAlternatively, could we make getSubTree/Paths() not throw, and only return empty result when the resource is not available?"
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 11,
                    "reviewer": {
                        "name": "Matt Spinler",
                        "email": "spinler@us.ibm.com",
                        "username": "spinler"
                    },
                    "message": "I like the idea of just returning an empty result when in progress, which is what would be returned anyway if you called before the introspect started."
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 11,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> That's why I only add this logic in `GetSubTreePaths` for now.\n\nbmcweb uses GetSubTreePaths as well, so this doesn't really solve the issue.  FWIW, we need a solution that works for all the mapper methods.\n\n\n> When it's in InProgressIntrospect and not available to the `GetSubTreePaths`, it will throw because getSubTreePaths() throws when there is no resource.\n\nIMO, it's very different.  \"This element doesn't exist yet\" is an error that every implementation already has to handle, because the system might not have that device/path, and in general, doesn't need to be retried.  \"Can't give a correct result yet\" errors arguably need to be retried.\n\n> I like the idea of just returning an empty result when in progress,\n\nI think we're saying the same thing, but we shouldn't return an EMPTY result, we should just omit the one service being introspected.  Ideally we'd do this by atomically adding all the paths in one shot, when the last handler calls back, instead of adding them as the results come in.  We do this pattern in other contexts like dbus-sensors (admittedly with a timer, but same idea)."
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 11,
                    "reviewer": {
                        "name": "Matt Spinler",
                        "email": "spinler@us.ibm.com",
                        "username": "spinler"
                    },
                    "message": "> I think we're saying the same thing, but we shouldn't return an EMPTY result, we should just omit the one service being introspected.  Ideally we'd do this by atomically adding all the paths in one shot, when the last handler calls back, instead of adding them as the results come in.  We do this pattern in other contexts like dbus-sensors (admittedly with a timer, but same idea).\n\nsounds good to me."
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 17,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This is going to force EVERY daemon in openbmc to add retry code for any mapper call.  In terms of complexity, I suspect that's not what we want."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Lei YU",
                        "email": "yulei.sh@bytedance.com",
                        "username": "mine260309"
                    },
                    "message": "@Ed Possibly let's discuss the issue in the mailing list to get an agreed solution, and go back to this gerrit to update the code."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "I thought about this some more, and I really suspect that this is just exposing a design issue in the IPMI logs implementation.\n\nIn terms of using the mapper this way, logs can:\n1. Be created at any time.\n2. Be created by any number of daemons.\n3. Aren't required by dbus to be created or destroyed in any kind of useful \"order\" given #2\n\nThis means that any code using the mapper needs to handle cases where logs are disjoint, given that that same race condition can occur between daemons, or at the time a log is created.\n\nIf the IPMI implementation can't handle that, this implies that it has bugs it needs to resolve, or shouldn't be using the mapper, because it would require guarantees that the mapper can't give if logs are spread across applications.\n\n\nAnother thing I wonder is would this issue be at least made better by the logging service zero padding their numbered results (ie 0001, instead of 1) such that alphabetically in the dbus sort, entry 2 gets introspected before 11.  Maybe that would give more consistent behavior in terms of \"logs are always added in order for a given daemon\".  There will always be an opportunity for them to be incomplete, but at least they look like they're append only on startup.\n\n"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I wouldn't be surprised if there are issues in the IPMI logging code, but how did you jump to this even being related to IPMI?  I haven't seen any previous mention of IPMI.\n\nThe busctl scenario in [1] (from the commit message) shows mapper giving answers of { 47, 375, 851, 1000 }.  The only valid answer was 1000 (and arguably 0).  I 100% agree that applications need to be able to deal with objects coming and going at any point in time, but we should generally at least give causal guarantees."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "> I haven't seen any previous mention of IPMI.\n\nI guess Lei YU did mention:\n\n> ipmid, the \"cached SEL\" feature depends on the reliable result\n> of GetSubTreePath, to get the number of current logging entries. If\n> it's not correct, ipmid will not know the \"missed\" entries.\n\nI'm not sure what that means.  Lei YU, can you expand on this?  How would ipmid handle if someone came in over Redfish and deleted an entry in between the mapper query and the phosphor-logging query?"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Brad Bishop",
                        "email": "bradleyb@fuzziesquirrel.com",
                        "username": "bradbishop"
                    },
                    "message": "FWIW, some possibly relevant historical background.\n\nOriginally, the python mapper blocked callers while it was introspecting, and it could only introspect one service at a time.  This meant the mapper introspected all services at startup serially, and there were deadlocks between applications starting up and calling the mapper, and the mapper trying to introspect those starting services.\n\nThat had responsiveness issues, so this series added \"non blocking discovery\" which basically returned EBUSY to callers if the mapper was in the middle of introspecting a new service (more or less what Lei Yu has proposed again with this patch):\n\nhttps://gerrit.openbmc.org/c/openbmc/phosphor-objmgr/+/577\n\nThat still had problems though, so we _really_ got creative with this one:\n\nhttps://gerrit.openbmc.org/c/openbmc/phosphor-objmgr/+/2694\n\nThis is where the causal ordering guarantee was dropped from the python mapper generally, but there was still a hacky way to do it for the mapper command line application.\n\nA couple unrelated, half baked thoughts:\n\nWith the c++ mapper being much more responsive, I wonder if it would make sense to go back to blocking callers while it introspects?\n\nWhat about having applications be explicit in informing the mapper they are ready to be introspected?  Something like sd_notify but for the mapper?  Does that help any?"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Lei YU",
                        "email": "yulei.sh@bytedance.com",
                        "username": "mine260309"
                    },
                    "message": "> If the IPMI implementation can't handle that, this implies that it has bugs it needs to resolve, or shouldn't be using the mapper, because it would require guarantees that the mapper can't give if logs are spread across applications.\n\nThe ipmid SEL cache handler handles the above cases well. The issue occurs on BMC boot when ipmid and phosphor-logging are starting, where mapper gives incomplete result.\n\n> Another thing I wonder is would this issue be at least made better by the logging service zero padding their numbered results (ie 0001, instead of 1) such that alphabetically in the dbus sort, entry 2 gets introspected before 11.  Maybe that would give more consistent behavior in terms of \"logs are always added in order for a given daemon\".  There will always be an opportunity for them to be incomplete, but at least they look like they're append only on startup.\n\nYes this is a bug in phosphor-logging where it uses the `filesystem order` to create the entries. This bug is not related to the \"mapper incomplete result\" though.\n\n> The busctl scenario in [1] (from the commit message) shows mapper giving answers of { 47, 375, 851, 1000 }.  The only valid answer was 1000 (and arguably 0).\n\nThis is exactly the issue here.\n\n> I'm not sure what that means.  Lei YU, can you expand on this?  How would ipmid handle if someone came in over Redfish and deleted an entry in between the mapper query and the phosphor-logging query?\n\nThe mapper query happens only on ipmid's startup. When it's done, it only gets interfacesAdded/Removed or propertiesChanged signal callbacks."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Lei YU",
                        "email": "yulei.sh@bytedance.com",
                        "username": "mine260309"
                    },
                    "message": "> With the c++ mapper being much more responsive, I wonder if it would make sense to go back to blocking callers while it introspects?\n\nI guess no. It takes quite a few seconds if a service has many objects to introspect, and blocking a caller for a few seconds is not a good idea.\n\n> What about having applications be explicit in informing the mapper they are ready to be introspected?  Something like sd_notify but for the mapper?  Does that help any?\n\nIn the phosphor-logging case, it is ready for mapper to introspect, it just takes mapper a few (or maybe more than ten if BMC is busy) seconds to introspect. And during this, the mapper gives incomplete result when the introspect is ongoing."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Matt Spinler",
                        "email": "spinler@us.ibm.com",
                        "username": "spinler"
                    },
                    "message": "What's wrong with Ed's proposal of just having mapper not add the new interfaces/paths into 'the Map' until the InProgressIntrospect destructor?"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Brad Bishop",
                        "email": "bradleyb@fuzziesquirrel.com",
                        "username": "bradbishop"
                    },
                    "message": "> What's wrong with Ed's proposal of just having mapper not add the new interfaces/paths into 'the Map' until the InProgressIntrospect destructor?\n\nNothing that I can tell.  I missed it initially."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> I wouldn't be surprised if there are issues in the IPMI logging code, but how did you jump to this even being related to IPMI?  I haven't seen any previous mention of IPMI.\n\nOn the mailing list, it was reported that this interfered with the \"sel cache\" feature, which I don't have any idea what it is, but I'm assuming is trying to cache log entries in the ipmi daemon.\n\n> The only valid answer was 1000 (and arguably 0).  \n\nI'm assuming the objects in the logger are added one at a time (I don't know of how to \"batch add\" objects in objectmanager), so the numbers between 0-1000 are valid, and could occur anyway if I just added logs while the thing was starting up, right?\n\n\n> With the c++ mapper being much more responsive, I wonder if it would make sense to go back to blocking callers while it introspects?\n\nI don't think this flies, as it makes the mapper only as fast as the slowest-to-introspect client, and there are some SLOOOOOOOOW clients out there that do blocking io in the event loop, so I'm not sure that works.\n\n\n> The ipmid SEL cache handler handles the above cases well. The issue occurs on BMC boot when ipmid and phosphor-logging are starting, where mapper gives incomplete result.\n\nCan you elaborate on this some more?  The \"incomplete\" result would look the same as log entries being added to the system, right?\n\n\n> Yes this is a bug in phosphor-logging where it uses the `filesystem order` to create the entries. This bug is not related to the \"mapper incomplete result\" though.\n\nThis seems like the core of the problem here.  If phosphor-logging on startup is creating entries in a randomized order (creates object id 1, then 11, then 2, ect) then there isn't much the mapper can do to give a \"complete\" result at any given point in time, right?  Can we start by getting that bug fixed, and see if that helps?\n\n\n> The mapper query happens only on ipmid's startup. When it's done, it only gets interfacesAdded/Removed or propertiesChanged signal callbacks.\n\nThe way this is described, you're duplicating mapper functionality in ipmi?  This seems like the core of the problem.  The mapper listens on InterfacesAdded/Removed, and keeps the list up to date, avoiding as many race conditions as it's able.  The expectation is that ipmi would call the mapper anytime it needs the data on available paths.\n\n\n\n\n\nIf we want to make the initial add of objects atomic like I proposed, I guess I'm ok with it, as it helps for other things and makes things appear more sane, but the way this feature is described, and how phosphor-logging seems to be implemented (adding logs in randomized order) seem like design issues that should be fixed in their respective daemons."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Matt Spinler",
                        "email": "spinler@us.ibm.com",
                        "username": "spinler"
                    },
                    "message": "I don't think I follow, how is the naming/ordering of log entry objects important?\n\nThe mapper would still return a subset of the total number of dbus objects if it's being queried in the middle of an introspect, why does it matter which ones they are?"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "> I don't think I follow, how is the naming/ordering of log entry objects important?\n\nRight, but if the subset is monotonically increasing one item at a time, its identical to logs getting added at runtime, which the implementation has to deal with anyway.  Yes, a user querying on startup might get an incomplete result, but considering they have to account for logs being added as well, it seems like stuff should \"just work\"."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Brad Bishop",
                        "email": "bradleyb@fuzziesquirrel.com",
                        "username": "bradbishop"
                    },
                    "message": "> its identical to logs getting added at runtime\n\nit isn't identical though.  At startup, a name owner changed signal is emitted just one time, for the entire 1000 objects.  At runtime, interfaces added / removed signals are emitted as interfaces come and go."
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Do we not make unique named connections available in the mapper today?  For some reason I thought we didn't make a distinction between well named and unique named in this case?"
                },
                {
                    "file": "/PATCHSET_LEVEL",
                    "line": 0,
                    "reviewer": {
                        "name": "Matt Spinler",
                        "email": "spinler@us.ibm.com",
                        "username": "spinler"
                    },
                    "message": "we explicitly skip sending interfaces added signals when we are restoring the logs from files, and then claim the bus name after that."
                },
                {
                    "file": "src/main.cpp",
                    "line": 27,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "I don't think this can be a set.  In theory, a process can be in introspect multiple times."
                },
                {
                    "file": "src/main.cpp",
                    "line": 27,
                    "reviewer": {
                        "name": "Lei YU",
                        "email": "yulei.sh@bytedance.com",
                        "username": "mine260309"
                    },
                    "message": "OK, we could use unordered_multiset's insert() and extract() instead."
                },
                {
                    "file": "src/main.cpp",
                    "line": 28,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "Putting this in another comment to avoid derailing the other thread.\n\nA little more digging shows that in phosphor-logging, ObjectManager is added prior to requesting the name, which means that the mapper is probably not calling Introspect but is using InterfacesAdded signals as each log entry is added (assuming the mapper starts first, which seems likely).\n\nIf I understand that correctly, this means that this patchset only appears to avoid the race, because InterfacesAdded signals are being sent all the time, and just happen to overlap with the requests while being processed one at a time by the mapper.  It doesn't look like it would actually solve it, because the phosphor-logging startup looks like:\n\nConnect to dbus\ninstantiate ObjectManager path and interface\nfor object on disk:\n   Add object\n   Emit InterfacesAdded\n   \n   \nRequest name (not sure if this is actually before or after adding objects, but it doesn't really matter).\n\nThis means that from a dbus perspective, objects are being created one at a time, which is why this race occurs.  Given that behavior of phosphor-logging, I'm not really sure how to fix it in the mapper, given that the phosphor-logging startup looks identical to an empty set of logs getting filled up (with the exception that the order appears randomized)."
                },
                {
                    "file": "src/main.cpp",
                    "line": 28,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "> A little more digging shows that in phosphor-logging, ObjectManager is added prior to requesting the name\n\nFrom a dbus perspective this is 100% the right behavior. \n\n1. add object manager \n2. create static objects\n3. reserve bus name\n\nIf you see daemons NOT doing it in that order we need to get them fixed."
                },
                {
                    "file": "src/main.cpp",
                    "line": 28,
                    "reviewer": {
                        "name": "Brad Bishop",
                        "email": "bradleyb@fuzziesquirrel.com",
                        "username": "bradbishop"
                    },
                    "message": "> but it doesn't really matter\n\nIt does matter though.  Well behaving dbus servers don't emit signals prior to claiming a well-known busname.\n\n> From a dbus perspective this is 100% the right behavior.\n\n+1"
                },
                {
                    "file": "src/main.cpp",
                    "line": 28,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": ">If you see daemons NOT doing it in that order we need to get them fixed.\n\nAgreed.\n\n\nSo is the fix here that we need to avoid returning results for daemons that haven't requested a name yet?"
                },
                {
                    "file": "src/main.cpp",
                    "line": 28,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "> So is the fix here that we need to avoid returning results for daemons that haven't requested a name yet?\n\nDoesn't mapper already do this?  I thought we even had filtering of specific service domain names so we were not interrogating all the org.freedesktop stuff?"
                },
                {
                    "file": "src/main.cpp",
                    "line": 28,
                    "reviewer": {
                        "name": "Matt Spinler",
                        "email": "spinler@us.ibm.com",
                        "username": "spinler"
                    },
                    "message": "It's still the original problem - as the mapper is introspecting and adding objects to its map after a name was requested, which can take a while when there is a lot of objects, other daemons may be asking the mapper for those objects"
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 29,
                    "deletions": 0
                },
                {
                    "file": "src/main.cpp",
                    "type": "MODIFIED",
                    "insertions": 19,
                    "deletions": 0
                }
            ],
            "sizeInsertions": 48,
            "sizeDeletions": 0
        }
    ]
}