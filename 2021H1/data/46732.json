{
    "project": "openbmc/openbmc",
    "branch": "master",
    "id": "I7f2e64e6d6f5930824e14b99fe0f47159fa64067",
    "number": 46732,
    "subject": "meta-hpe: Synchronization commit",
    "owner": {
        "name": "Mike Garrett",
        "email": "mike.garrett@hpe.com",
        "username": "mgarrett33"
    },
    "url": "https://gerrit.openbmc-project.xyz/c/openbmc/openbmc/+/46732",
    "commitMessage": "meta-hpe: Synchronization commit\n\nThis is a large sync commit to align upstream with HPE's public repo at https://github.com/HewlettPackard/openbmc\nThe patch files have been omitted to maximize the durability of this build to changes in the rest of the upstream.\n\nSigned-off-by: Mike Garrett <mike.garrett@hpe.com>\nChange-Id: I7f2e64e6d6f5930824e14b99fe0f47159fa64067\n",
    "createdOn": 1631197482,
    "lastUpdated": 1631619083,
    "open": false,
    "status": "ABANDONED",
    "comments": [
        {
            "timestamp": 1631197482,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Uploaded patch set 1."
        },
        {
            "timestamp": 1631197516,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 1: Ok-To-Test+1\n\nUser approved, CI ok to start"
        },
        {
            "timestamp": 1631197526,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 1:\n\nBuild Started https://jenkins.openbmc.org/job/ci-openbmc/6591/"
        },
        {
            "timestamp": 1631198890,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\nThis change is ready for review."
        },
        {
            "timestamp": 1631199916,
            "reviewer": {
                "name": "OpenBMC CI",
                "email": "openbmcbump-ci@yahoo.com",
                "username": "jenkins-openbmc-ci"
            },
            "message": "Patch Set 1: Verified+1\n\nBuild Successful \n\nhttps://jenkins.openbmc.org/job/ci-openbmc/6591/ : SUCCESS"
        },
        {
            "timestamp": 1631199969,
            "reviewer": {
                "name": "Jorge Cisneros",
                "email": "jcisneros3@lenovo.com",
                "username": "jorgecis"
            },
            "message": "Patch Set 1: Code-Review+2"
        },
        {
            "timestamp": 1631200027,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1: Code-Review-2\n\n(8 comments)\n\nMarking -2 to prevent immediate merge."
        },
        {
            "timestamp": 1631200097,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\nI think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers."
        },
        {
            "timestamp": 1631200161,
            "reviewer": {
                "name": "Jorge Cisneros",
                "email": "jcisneros3@lenovo.com",
                "username": "jorgecis"
            },
            "message": "Patch Set 1: -Code-Review"
        },
        {
            "timestamp": 1631200654,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n> Patch Set 1:\n> \n> I think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers.\n\nSure - I'd love to hear what is considered deviation from best practices (beside the fact its a big commit...I know this part).  This is what we have working with one of our partners and I'm not aware of which recipes are not approved of."
        },
        {
            "timestamp": 1631201035,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(7 comments)\n\n> Patch Set 1:\n> \n> > Patch Set 1:\n> > \n> > I think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers.\n> \n> Sure - I'd love to hear what is considered deviation from best practices (beside the fact its a big commit...I know this part).  This is what we have working with one of our partners and I'm not aware of which recipes are not approved of.\n\nWrote this before I saw your specific feedback."
        },
        {
            "timestamp": 1631201437,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n> Sure - I'd love to hear what is considered deviation from best practices (beside the fact its a big commit...I know this part).  This is what we have working with one of our partners and I'm not aware of which recipes are not approved of.\n\nOverall we've tried to document them here:\n    https://github.com/openbmc/docs/blob/master/meta-layer-guidelines.md\n\nI think you're already aware of \"don't patch existing code\", since you mentioned filtering that out.  Adding config files to meta-layers when the underlying repository is expecting config files present inside it is basically another form of patching.  The EM config fits this.\n\nYou have a number of recipes, which I've tried to make mention of, which are pointing to your own repos.  This violates the intent of \"5. Meta layers recipes should only point to well maintained open source projects\" even if you consider your own repositories \"well maintained\".  If you read the paragraph in it it says:\n\n> Without this guideline, a loophole is present that allows OpenBMC developers to  \n> bypass code review by pointing the upstream recipe to a public repository that   \n> they control, but which OpenBMC has no input on the content of.  This splits the \n> discussion forums in unproductive ways, and prevents all the other good          \n> processes within OpenBMC like bug tracking and continuous integration from       \n> having an effect.\n\nWe've been a little flexible on this last guideline (too much in my opinion) but your recipes like \"gxp-dbus-sensors\" is pushing the boundary pretty far."
        },
        {
            "timestamp": 1631201529,
            "reviewer": {
                "name": "Jenkins OpenBMC IBM",
                "email": "geissonator+jenkinsibm@gmail.com",
                "username": "jenkins-openbmc-ibm"
            },
            "message": "Patch Set 1:\n\nBuild Failed \n\nIBM Hardware CI : witherspoon hardware test failed"
        },
        {
            "timestamp": 1631201944,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631202315,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631202362,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631202433,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(7 comments)"
        },
        {
            "timestamp": 1631202847,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631202886,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631203125,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(2 comments)"
        },
        {
            "timestamp": 1631203271,
            "reviewer": {
                "name": "Jenkins OpenBMC IBM",
                "email": "geissonator+jenkinsibm@gmail.com",
                "username": "jenkins-openbmc-ibm"
            },
            "message": "Patch Set 1:\n\nBuild Successful \n\nIBM Hardware CI : witherspoon hardware tests passed"
        },
        {
            "timestamp": 1631204009,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631205959,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1: Code-Review-2\n\n(1 comment)"
        },
        {
            "timestamp": 1631211256,
            "reviewer": {
                "name": "Jean-Marie Verdun",
                "email": "jean-marie.verdun@hpe.com",
                "username": "vejmarie"
            },
            "message": "Patch Set 1:\n\n> Patch Set 1:\n> \n> I think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers.\n\nHi Patrick. I agree big PR is never the best practice. Our challenge is that we need to recover and integrate a ton of works which has been done lately in HPE. It would be great if that PR could go through and we sort out issues with time going on. meta-hpe is under super active development as you can see through this PR and if we break it in dozens of potential upcoming PR, we won't be integrating that code fast enough."
        },
        {
            "timestamp": 1631216759,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n> Patch Set 1:\n> \n> > Patch Set 1:\n> > \n> > I think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers.\n> \n> Hi Patrick. I agree big PR is never the best practice. Our challenge is that we need to recover and integrate a ton of works which has been done lately in HPE.\n\nGreat.  Glad to hear work is being done, but I'm not understanding why \"recovering\" would necessitate one massive commit, copying and pasting functionality, and breaking the meta layer rules.  Maybe I missed something?\n\n> It would be great if that PR could go through and we sort out issues with time going on.\n\nWith respect, that would be great for HPE, but bad for the project overall, and force others to do the cleanup.  As-written, IMO this patchset can't go forward.\n\n> meta-hpe is under super active development as you can see through this PR and if we break it in dozens of potential upcoming PR, we won't be integrating that code fast enough.\n\nI'm not following why that's a problem.  Discussions with upstream, and other users of the same code, while not fast, helps the project move along, and stay maintainable for more than just HPE."
        },
        {
            "timestamp": 1631216895,
            "reviewer": {
                "name": "Ed Tanous",
                "email": "ed@tanous.net",
                "username": "edtanous"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631217302,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631224228,
            "reviewer": {
                "name": "Jean-Marie Verdun",
                "email": "jean-marie.verdun@hpe.com",
                "username": "vejmarie"
            },
            "message": "Patch Set 1:\n\n> Patch Set 1:\n> \n> > Patch Set 1:\n> > \n> > > Patch Set 1:\n> > > \n> > > I think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers.\n> > \n> > Hi Patrick. I agree big PR is never the best practice. Our challenge is that we need to recover and integrate a ton of works which has been done lately in HPE.\n> \n> Great.  Glad to hear work is being done, but I'm not understanding why \"recovering\" would necessitate one massive commit, copying and pasting functionality, and breaking the meta layer rules.  Maybe I missed something?\n> \n> > It would be great if that PR could go through and we sort out issues with time going on.\n> \n> With respect, that would be great for HPE, but bad for the project overall, and force others to do the cleanup.  As-written, IMO this patchset can't go forward.\n> \n> > meta-hpe is under super active development as you can see through this PR and if we break it in dozens of potential upcoming PR, we won't be integrating that code fast enough.\n> \n> I'm not following why that's a problem.  Discussions with upstream, and other users of the same code, while not fast, helps the project move along, and stay maintainable for more than just HPE.\n\nHi Ed,\n\nWe will break down the PR for sure. I am not a master of yocto, but as all the modifications were into meta-hpe, I got the feeling that the pain was containerized into meta-hpe without impacting upstream or other platforms, and getting the work on our back if something break. \n\nWe have a ton of code clean up to do, and still a lot of things to implement. I am fearing it could take weeks / months to our small team to recover, but that is ok.\n\nvejmarie"
        },
        {
            "timestamp": 1631279812,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Patch Set 1:\n\n> Patch Set 1:\n> \n> > Patch Set 1:\n> > \n> > > Patch Set 1:\n> > > \n> > > > Patch Set 1:\n> > > > \n> > > > I think we should discuss some of these recipes before we just put it in.  There is a lot of code here and a lot of it is a deviation from best-practices.  Maybe we let it in as-is with some agreement towards fixing things up in the future, but I'd like to hear what the consensus is from some of the other maintainers.\n> > > \n> > > Hi Patrick. I agree big PR is never the best practice. Our challenge is that we need to recover and integrate a ton of works which has been done lately in HPE.\n> > \n> > Great.  Glad to hear work is being done, but I'm not understanding why \"recovering\" would necessitate one massive commit, copying and pasting functionality, and breaking the meta layer rules.  Maybe I missed something?\n> > \n> > > It would be great if that PR could go through and we sort out issues with time going on.\n> > \n> > With respect, that would be great for HPE, but bad for the project overall, and force others to do the cleanup.  As-written, IMO this patchset can't go forward.\n> > \n> > > meta-hpe is under super active development as you can see through this PR and if we break it in dozens of potential upcoming PR, we won't be integrating that code fast enough.\n> > \n> > I'm not following why that's a problem.  Discussions with upstream, and other users of the same code, while not fast, helps the project move along, and stay maintainable for more than just HPE.\n> \n> Hi Ed,\n> \n> We will break down the PR for sure. I am not a master of yocto, but as all the modifications were into meta-hpe, I got the feeling that the pain was containerized into meta-hpe without impacting upstream or other platforms, and getting the work on our back if something break. \n> \n> We have a ton of code clean up to do, and still a lot of things to implement. I am fearing it could take weeks / months to our small team to recover, but that is ok.\n> \n> vejmarie\n\nI will abandon this review and start feeding in small reviews over time.  I took several comments back for consideration as well."
        },
        {
            "timestamp": 1631279869,
            "reviewer": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "message": "Abandoned\n\nWill resubmit over time as smaller changesets."
        },
        {
            "timestamp": 1631291739,
            "reviewer": {
                "name": "Jorge Cisneros",
                "email": "jcisneros3@lenovo.com",
                "username": "jorgecis"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        },
        {
            "timestamp": 1631619083,
            "reviewer": {
                "name": "Patrick Williams",
                "email": "patrick@stwcx.xyz",
                "username": "williamspatrick"
            },
            "message": "Patch Set 1:\n\n(1 comment)"
        }
    ],
    "patchSets": [
        {
            "number": 1,
            "revision": "bab095b780e9269363e70550dfe3700732c9b5b5",
            "parents": [
                "aa7e21d81a85ea70b24108f190ac020cff5270a9"
            ],
            "ref": "refs/changes/32/46732/1",
            "uploader": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "createdOn": 1631197482,
            "author": {
                "name": "Mike Garrett",
                "email": "mike.garrett@hpe.com",
                "username": "mgarrett33"
            },
            "kind": "REWORK",
            "comments": [
                {
                    "file": "/COMMIT_MSG",
                    "line": 7,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "This commit very clearly needs broken up into its constituent parts.  Given the title of this being \"syncronize\" I would expect that's known by the author, considering this is clearly months worth of development squashed into a 4000+ line review.\n\nBeyond that, it breaks several of the meta layer guidelines.  Lets start by getting this broken up into something that's actually reviewable, and get emails sent to the list for the relevant copied functionality, so we can figure out how to not copy/paste generic features into meta-hpe."
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 10,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "Can we get future work to be done upstream and/or submitted as individual commits?  It isn't great from a git-history perspective to have big commits like this without much explanation why."
                },
                {
                    "file": "/COMMIT_MSG",
                    "line": 10,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "Ack"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/libpeci/libpeci_git.bb",
                    "line": 8,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I think this recipe isn't in meta-phosphor already because there were issues with the repo...  We probably shouldn't add this one in a machine-specific meta."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/libpeci/libpeci_git.bb",
                    "line": 8,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "OK - great feedback.  I'm not sure how we can find out ahead of time the disposition of some of these.  I will remove it."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/libpeci/libpeci_git.bb",
                    "line": 8,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "This was added because its a dependency of smbios-mdr which we also want to integrate.  We are currently using the CHIF service to download SMBIOS at POST and parse it using the SMBIOS recipe to populate DIMMs and other things."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/libpeci/libpeci_git.bb",
                    "line": 8,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "If you see a repository in openbmc (or especially Intel-BMC) that doesn't have a recipe written and/or you don't see another machine using it, it is probably good to ask \"what's going on with ...\"  People are pretty regularly around on Discord if you want fast feedback.\n\nPECI has been contentious because it was in the openbmc kernel and then pulled out because Intel didn't finish upstreaming it.  That caused us to have to pull everything related to PECI until they figure it out, which is unfortunate because PECI is obviously pretty important for Intel chips."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/acm/acm_0.1.bb",
                    "line": 6,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I really don't like seeing tons of these HP specific repositories, some of which are seemingly forks of other repositories."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/acm/acm_0.1.bb",
                    "line": 6,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "ACM is an interface to an HPE specific bit of chassis hardware.  No chance its broadly applicable."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/acm/acm_0.1.bb",
                    "line": 6,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "This is not a fork of anything."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/acm/acm_0.1.bb",
                    "line": 6,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I think there are a few other vendors that are in similar boats and we don't have a good / consistent story on it.  In some cases we've given separate repositories, in some cases we've asked them to put pieces (as appropriate) into specific repositories with #ifdefs, and in some cases we've let them maintain their own repository like you've done here.\n\nI wish we had more consistency in the answer.\n\nIt would be good to have some brief write up on what these do.  I feel like people are quick to say \"what I'm doing is unique\" because that is obviously easier, but it also means the code deviates and when we need to make pervasive changes we have exponentially more code to sift through.  When that code isn't even in an openbmc repository it increases the effort even more.\n\nIdeally we figure out a good abstraction level between the software-oriented bits and the hardware-oriented bits and ensure that we have commonality on the software pieces and some structure for allowing hardware bits to get in quickly."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/acm/acm_0.1.bb",
                    "line": 6,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "I'd be happy to write it up.  Would it make sense to put in in comments in the recipe file itself?  Or in the repo?  Basically its code that communicates suggested fan RPM values to our Apollo 2000 Chassis Manager."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-chif-service/gxp-chif-service_0.1.bb",
                    "line": 2,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "What is \"CHIF\"?"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-chif-service/gxp-chif-service_0.1.bb",
                    "line": 2,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "HPE's proprietary BIOS (and runtime) interface.  Our BIOS communicates to iLO 5 using CHIF (channel interface).  There's almost no chance we are going to refactor the BIOS away from this, so our best option is to enable it in our OpenBMC build."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-chif-service/gxp-chif-service_0.1.bb",
                    "line": 2,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "Understand.  This is pretty similar story to the ACM commit then."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-chif-service/gxp-chif-service_0.1.bb",
                    "line": 2,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "Am I supposed to mark resolved or so you?"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-chif-service/gxp-chif-service_0.1.bb",
                    "line": 2,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "Done"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-dbus-sensors/gxp-dbus-sensors_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "Why isn't this work being done in dbus-sensors directly?  Is there really anything special about gxp here?"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-dbus-sensors/gxp-dbus-sensors_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "Yes - its reading an internal SOC core temp value, not an I2C temp sensor."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-dbus-sensors/gxp-dbus-sensors_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "I need to check to see if this subsumes any of the dbus-sensors stuff too but I know it has some SOC specific functionality not present in any other imlementation."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-dbus-sensors/gxp-dbus-sensors_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I assume you have an hwmon interface for that, so it shouldn't matter what hardware protocol is being used to get at the sensor.  I skimmed through the code and it indeed looks like it is all hwmon stuff, so I'm not understanding what is \"special\"."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-fru-device/gxp-fru-device_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I also didn't remark on every single recipe here.  This one feels like a fork of part of the EM repository."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/smbios-mdr/smbios-mdr_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "Another openbmc repo without a recipe (but I think there is one now or it is in progress in Gerrit)."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/smbios-mdr/smbios-mdr_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "Right - but this relies upon libpeci - so if libpeci isn't ready, are we unable to include this one too?"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/smbios-mdr/smbios-mdr_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "Right - but this relies upon libpeci - so if libpeci isn't ready, are we unable to include this one too?"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/smbios-mdr/smbios-mdr_0.1.bb",
                    "line": 4,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "This recipe is upstreamed now, so let's shift to using that.\n\n  $ cat ./meta-phosphor/recipes-phosphor/smbios/smbios-mdr_git.bb | grep peci  \n  PACKAGECONFIG[cpuinfo] = \"-DCPU_INFO=ON,-DCPU_INFO=OFF,libpeci i2c-tools\"\n\nThe peci package is, unfortunately in Intel's meta layer.\n\n  $ find -name \"libpeci*.bb\"             \n  ./meta-intel-openbmc/meta-common/recipes-core/libpeci/libpeci_git.bb\n\nLet's see if we can just move their recipe to meta-phosphor."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager_%.bbappend",
                    "line": 12,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "I don't think we want EM config in the meta layers.  It is intended to be in the repository itself."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager_%.bbappend",
                    "line": 12,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "For server systems wouldn't it be good to have as much of the machien build specifics as possible in the layer?  We were actually moving in the opposite direction of having the dl360g10.json file live in the meta-dl360poc layer."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager_%.bbappend",
                    "line": 12,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "You should discuss with Ed Tanous (EM maintainer).  His current opinion is that all EM config belongs in the EM repository.  This makes it easier to refactor as needed.\n\n(I understand both perspectives on this, but that is his current direction.)"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager_%.bbappend",
                    "line": 12,
                    "reviewer": {
                        "name": "Ed Tanous",
                        "email": "ed@tanous.net",
                        "username": "edtanous"
                    },
                    "message": "All configs belong in EM because EM is designed and capable of supporting runtime based system detection, so in practice, the config files aren't \"system specific\".  It also helps with maintenance when we need to make breaking changes to the schema, and verify schema correctness (the repo CI runs all these checks automatically on pushes).  Those same checks can't be done in a meta layer."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/initrdscripts/files/gxp-obmc-update.sh",
                    "line": 1,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "Why do you have your own \"update via shell\" mechanism rather than using phosphor-bmc-code-mgmt?"
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/initrdscripts/files/gxp-obmc-update.sh",
                    "line": 1,
                    "reviewer": {
                        "name": "Jorge Cisneros",
                        "email": "jcisneros3@lenovo.com",
                        "username": "jorgecis"
                    },
                    "message": "> Why do you have your own \"update via shell\" mechanism rather than using phosphor-bmc-code-mgmt?\n\nThis is not our own script, this is just an updated version of your own script, you can find it here meta-phosphor/recipes-phosphor/initrdscripts/files/obmc-update.sh\n\nThis script is almost the same with some new partitions and support for our secure boot solution."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/initrdscripts/files/gxp-obmc-update.sh",
                    "line": 1,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "> This is not our own script, this is just an updated version of your own script, you can find it here meta-phosphor/recipes-phosphor/initrdscripts/files/obmc-update.sh\n\nI misunderstood the origin of it then, sorry.\n\n> This script is almost the same with some new partitions and support for our secure boot solution.\n\nWe still should figure out how to make it common.  New file systems should be able to be handled by something like a `sed` call in the do_install:append.  I'd have to look in details about the secure-boot specifics, but I'm not really wanting to search them out directly myself."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-support/rng-tools/rng-tools_%.bbappend",
                    "line": 1,
                    "reviewer": {
                        "name": "Patrick Williams",
                        "email": "patrick@stwcx.xyz",
                        "username": "williamspatrick"
                    },
                    "message": "Why is this necessary?  We have meta-phosphor/recipes-support/rng-tools/rng-tools_%.bbappend already.  I think the only thing you should need to do is to set the 'hw-rng' MACHINE_FEATURE for your GXP hardware."
                },
                {
                    "file": "meta-hpe/meta-common/recipes-support/rng-tools/rng-tools_%.bbappend",
                    "line": 1,
                    "reviewer": {
                        "name": "Mike Garrett",
                        "email": "mike.garrett@hpe.com",
                        "username": "mgarrett33"
                    },
                    "message": "I'll check into this and replace if its equivalent."
                }
            ],
            "files": [
                {
                    "file": "/COMMIT_MSG",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/conf/layer.conf",
                    "type": "ADDED",
                    "insertions": 10,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-connectivity/virtualnic/files/LICENSE",
                    "type": "ADDED",
                    "insertions": 204,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-connectivity/virtualnic/files/virtualnic",
                    "type": "ADDED",
                    "insertions": 65,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-connectivity/virtualnic/files/virtualnic.service",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-connectivity/virtualnic/virtualnic.bb",
                    "type": "ADDED",
                    "insertions": 18,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/libpeci/libpeci_git.bb",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/os-release/os-release.bbappend",
                    "type": "ADDED",
                    "insertions": 45,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-core/systemd/obmc-targets.bbappend",
                    "type": "ADDED",
                    "insertions": 8,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-extended/rsyslog/rsyslog/rotate-event-logs.service",
                    "type": "ADDED",
                    "insertions": 9,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-extended/rsyslog/rsyslog/rotate-event-logs.timer",
                    "type": "ADDED",
                    "insertions": 8,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-extended/rsyslog/rsyslog/rsyslog-override.conf",
                    "type": "ADDED",
                    "insertions": 2,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-extended/rsyslog/rsyslog/rsyslog.conf",
                    "type": "ADDED",
                    "insertions": 52,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-extended/rsyslog/rsyslog/rsyslog.logrotate",
                    "type": "ADDED",
                    "insertions": 15,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-extended/rsyslog/rsyslog_%.bbappend",
                    "type": "ADDED",
                    "insertions": 17,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/acm/acm_0.1.bb",
                    "type": "ADDED",
                    "insertions": 28,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-chif-service/gxp-chif-service_0.1.bb",
                    "type": "ADDED",
                    "insertions": 18,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-dbus-sensors/gxp-dbus-sensors_0.1.bb",
                    "type": "ADDED",
                    "insertions": 20,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/gxp-fru-device/gxp-fru-device_0.1.bb",
                    "type": "ADDED",
                    "insertions": 19,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/packagegroups/packagegroup-hpe-apps.bb",
                    "fileOld": "meta-hpe/meta-common/recipes-phosphor/packagegroups/packagegroup-hpe-apps.bb",
                    "type": "RENAMED",
                    "insertions": 21,
                    "deletions": -8
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/recovery-image-validator/recovery-image-validator_0_1.bb",
                    "type": "ADDED",
                    "insertions": 31,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/smbios-mdr/smbios-mdr_0.1.bb",
                    "type": "ADDED",
                    "insertions": 35,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/uid-btn/uid-btn.bb",
                    "type": "ADDED",
                    "insertions": 29,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/uid-btn/uid-btn/obmc/gpio/uid_btn",
                    "type": "ADDED",
                    "insertions": 5,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/uid-btn/uid-btn/uid-btn.service",
                    "type": "ADDED",
                    "insertions": 11,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/uid-btn/uid-btn/uid-btn.sh",
                    "type": "ADDED",
                    "insertions": 10,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/vehci/host-ehci-owner-reset.bb",
                    "type": "ADDED",
                    "insertions": 45,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/vehci/host-ehci-owner-reset/host-ehci-owner-reset@.service",
                    "type": "ADDED",
                    "insertions": 11,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/vehci/host-ehci-owner-reset/obmc/gpio/port_owner_udc0",
                    "type": "ADDED",
                    "insertions": 5,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/vehci/host-ehci-owner-reset/obmc/gpio/port_owner_udc1",
                    "type": "ADDED",
                    "insertions": 5,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/vehci/host-ehci-owner-reset/obmc/gpio/port_owner_udc2",
                    "type": "ADDED",
                    "insertions": 5,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-hpe/vehci/host-ehci-owner-reset/udc-reconnect.sh",
                    "type": "ADDED",
                    "insertions": 37,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager/dl325g10p.json",
                    "type": "ADDED",
                    "insertions": 331,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager/dl360g10.json",
                    "type": "ADDED",
                    "insertions": 337,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager/xl225ng10p.json",
                    "type": "ADDED",
                    "insertions": 265,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/entity-manager_%.bbappend",
                    "type": "ADDED",
                    "insertions": 12,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/obmc-yaml-config.bb",
                    "type": "ADDED",
                    "insertions": 35,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/obmc-yaml-config/obmc-extra-properties.yaml",
                    "type": "ADDED",
                    "insertions": 25,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/obmc-yaml-config/obmc-fru-read.yaml",
                    "type": "ADDED",
                    "insertions": 61,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/obmc-yaml-config/obmc-inventory-sensor.yaml",
                    "type": "ADDED",
                    "insertions": 5,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/configuration/obmc-yaml-config/obmc-sensor.yaml",
                    "type": "ADDED",
                    "insertions": 1236,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/console/obmc-console/80-gxp-obmc-console-uart.rules",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/console/obmc-console_%.bbappend",
                    "type": "ADDED",
                    "insertions": 10,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/dbus/phosphor-dbus-monitor-config.bbappend",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/fans/phosphor-pid-control/phosphor-pid-control.service",
                    "type": "ADDED",
                    "insertions": 12,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/fans/phosphor-pid-control_%.bbappend",
                    "type": "ADDED",
                    "insertions": 6,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/flash/phosphor-software-manager/xyz.openbmc_project.Software.BMC.Updater.service",
                    "type": "ADDED",
                    "insertions": 16,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/flash/phosphor-software-manager_%.bbappend",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/host-post/phosphor-host-postd_%.bbappend",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/image/obmc-phosphor-image.bbappend",
                    "type": "DELETED",
                    "insertions": 0,
                    "deletions": -151
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/images/obmc-phosphor-image.bbappend",
                    "type": "ADDED",
                    "insertions": 241,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/images/obmc-phosphor-initramfs.bbappend",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/initrdscripts/files/gxp-obmc-init.sh",
                    "type": "MODIFIED",
                    "insertions": 47,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/initrdscripts/files/gxp-obmc-update.sh",
                    "type": "ADDED",
                    "insertions": 335,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/initrdscripts/obmc-phosphor-initfs.bbappend",
                    "type": "MODIFIED",
                    "insertions": 2,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/interfaces/bmcweb_%.bbappend",
                    "type": "ADDED",
                    "insertions": 3,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-config.bbappend",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-config/dcmi_sensors.json",
                    "type": "ADDED",
                    "insertions": 19,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-config/dev_id.json",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-config/power_reading.json",
                    "type": "ADDED",
                    "insertions": 3,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-fru_%.bbappend",
                    "type": "ADDED",
                    "insertions": 9,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-host/entity.yaml",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-host/xyz.openbmc_project.Ipmi.Internal.SoftPowerOff.service",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-host_%.bbappend",
                    "type": "ADDED",
                    "insertions": 22,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-ipmb/ipmb-channels.json",
                    "type": "ADDED",
                    "insertions": 10,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-ipmb_%.bbappend",
                    "type": "ADDED",
                    "insertions": 8,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-kcs/99-ipmi-kcs.rules",
                    "type": "ADDED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/ipmi/phosphor-ipmi-kcs_%.bbappend",
                    "type": "ADDED",
                    "insertions": 9,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/leds/hpe-g10p-common-led-manager-config-native.bb",
                    "type": "ADDED",
                    "insertions": 18,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/leds/hpe-g10p-common-led-manager-config/led.yaml",
                    "type": "ADDED",
                    "insertions": 27,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/network/first-boot-set-hostname.bb",
                    "type": "ADDED",
                    "insertions": 19,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/network/first-boot-set-hostname/first-boot-set-hostname.service",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/network/first-boot-set-hostname/first-boot-set-hostname.sh",
                    "type": "ADDED",
                    "insertions": 14,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/network/phosphor-network_%.bbappend",
                    "type": "ADDED",
                    "insertions": 2,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/network/snmp-native.bb",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/network/snmp/example.yaml",
                    "type": "ADDED",
                    "insertions": 271,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/packagegroups/packagegroup-obmc-apps.bbappend",
                    "type": "DELETED",
                    "insertions": 0,
                    "deletions": -10
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/sel-logger/phosphor-sel-logger_%.bbappend",
                    "type": "ADDED",
                    "insertions": 3,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/sensors/dbus-sensors_git.bbappend",
                    "type": "ADDED",
                    "insertions": 8,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/state/phosphor-state-manager_%.bbappend",
                    "type": "ADDED",
                    "insertions": 4,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-phosphor/watchdog/phosphor-watchdog/phosphor-watchdog_%.bbappend",
                    "type": "ADDED",
                    "insertions": 2,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-support/rng-tools/rng-tools/rngd.service",
                    "type": "ADDED",
                    "insertions": 13,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-common/recipes-support/rng-tools/rng-tools_%.bbappend",
                    "type": "ADDED",
                    "insertions": 8,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-dl360poc/conf/bblayers.conf.sample",
                    "type": "MODIFIED",
                    "insertions": 4,
                    "deletions": -2
                },
                {
                    "file": "meta-hpe/meta-dl360poc/conf/machine/dl360poc.conf",
                    "type": "MODIFIED",
                    "insertions": 1,
                    "deletions": -3
                },
                {
                    "file": "meta-hpe/meta-dl360poc/recipes-kernel/linux/linux-obmc/gxp.dts",
                    "type": "MODIFIED",
                    "insertions": 10,
                    "deletions": -1
                },
                {
                    "file": "meta-hpe/meta-gxp/recipes-bsp/u-boot/u-boot-common-gxp_2020.10.inc",
                    "type": "MODIFIED",
                    "insertions": 1,
                    "deletions": -1
                },
                {
                    "file": "meta-hpe/meta-gxp/recipes-kernel/linux/linux-obmc.inc",
                    "type": "MODIFIED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-gxp/recipes-kernel/linux/linux-obmc/defconfig",
                    "type": "MODIFIED",
                    "insertions": 1,
                    "deletions": 0
                },
                {
                    "file": "meta-hpe/meta-gxp/recipes-kernel/linux/linux-obmc_5.10.bb",
                    "type": "MODIFIED",
                    "insertions": 1,
                    "deletions": -1
                }
            ],
            "sizeInsertions": 4355,
            "sizeDeletions": 177
        }
    ]
}